<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url('https://themes.googleusercontent.com/fonts/css?kit=fpjTOVmNbO4Lz34iLyptLTi9jKYd1gJzj5O2gWsEpXq5DSxTUXlwXebxyXtT0rCwv1unUalIzurR1sLOY-mh2Q');ol.lst-kix_6vqbqdbyarbv-2.start{counter-reset:lst-ctn-kix_6vqbqdbyarbv-2 0}.lst-kix_yyogjecm4su2-0>li{counter-increment:lst-ctn-kix_yyogjecm4su2-0}.lst-kix_6vqbqdbyarbv-1>li{counter-increment:lst-ctn-kix_6vqbqdbyarbv-1}ul.lst-kix_list_1-0{list-style-type:none}.lst-kix_list_3-0>li:before{content:"   "}ol.lst-kix_yyogjecm4su2-3.start{counter-reset:lst-ctn-kix_yyogjecm4su2-3 0}ol.lst-kix_6vqbqdbyarbv-5.start{counter-reset:lst-ctn-kix_6vqbqdbyarbv-5 0}.lst-kix_list_3-1>li:before{content:"   "}.lst-kix_list_3-2>li:before{content:"   "}ol.lst-kix_list_1-8.start{counter-reset:lst-ctn-kix_list_1-8 0}ol.lst-kix_yyogjecm4su2-0.start{counter-reset:lst-ctn-kix_yyogjecm4su2-0 0}ul.lst-kix_list_1-3{list-style-type:none}.lst-kix_list_3-5>li:before{content:"   "}ul.lst-kix_list_1-4{list-style-type:none}ul.lst-kix_list_1-1{list-style-type:none}.lst-kix_list_3-4>li:before{content:"   "}ul.lst-kix_list_1-2{list-style-type:none}.lst-kix_list_3-3>li:before{content:"   "}ul.lst-kix_list_1-5{list-style-type:none}ol.lst-kix_list_3-7{list-style-type:none}ul.lst-kix_list_1-6{list-style-type:none}ol.lst-kix_list_3-8{list-style-type:none}.lst-kix_list_3-8>li:before{content:" "}.lst-kix_list_3-6>li:before{content:"   "}.lst-kix_list_3-7>li:before{content:" "}.lst-kix_6vqbqdbyarbv-0>li{counter-increment:lst-ctn-kix_6vqbqdbyarbv-0}.lst-kix_6vqbqdbyarbv-3>li{counter-increment:lst-ctn-kix_6vqbqdbyarbv-3}.lst-kix_yyogjecm4su2-2>li{counter-increment:lst-ctn-kix_yyogjecm4su2-2}.lst-kix_6vqbqdbyarbv-7>li:before{content:"" counter(lst-ctn-kix_6vqbqdbyarbv-0,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-1,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-2,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-3,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-4,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-5,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-6,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-7,decimal) ". "}ol.lst-kix_list_3-7.start{counter-reset:lst-ctn-kix_list_3-7 0}.lst-kix_6vqbqdbyarbv-6>li:before{content:"" counter(lst-ctn-kix_6vqbqdbyarbv-0,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-1,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-2,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-3,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-4,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-5,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-6,decimal) ". "}.lst-kix_6vqbqdbyarbv-8>li:before{content:"" counter(lst-ctn-kix_6vqbqdbyarbv-0,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-1,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-2,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-3,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-4,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-5,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-6,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-7,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-8,decimal) ". "}.lst-kix_6vqbqdbyarbv-1>li:before{content:"" counter(lst-ctn-kix_6vqbqdbyarbv-0,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-1,decimal) ". "}.lst-kix_6vqbqdbyarbv-3>li:before{content:"" counter(lst-ctn-kix_6vqbqdbyarbv-0,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-1,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-2,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-3,decimal) ". "}.lst-kix_6vqbqdbyarbv-2>li:before{content:"" counter(lst-ctn-kix_6vqbqdbyarbv-0,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-1,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-2,decimal) ". "}.lst-kix_list_4-8>li:before{content:" "}.lst-kix_6vqbqdbyarbv-5>li:before{content:"" counter(lst-ctn-kix_6vqbqdbyarbv-0,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-1,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-2,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-3,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-4,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-5,decimal) ". "}ol.lst-kix_6vqbqdbyarbv-7{list-style-type:none}.lst-kix_6vqbqdbyarbv-4>li{counter-increment:lst-ctn-kix_6vqbqdbyarbv-4}ol.lst-kix_6vqbqdbyarbv-8{list-style-type:none}.lst-kix_list_4-7>li:before{content:" "}ol.lst-kix_6vqbqdbyarbv-4.start{counter-reset:lst-ctn-kix_6vqbqdbyarbv-4 0}.lst-kix_6vqbqdbyarbv-4>li:before{content:"" counter(lst-ctn-kix_6vqbqdbyarbv-0,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-1,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-2,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-3,decimal) "." counter(lst-ctn-kix_6vqbqdbyarbv-4,decimal) ". "}ul.lst-kix_list_4-6{list-style-type:none}ol.lst-kix_list_4-8.start{counter-reset:lst-ctn-kix_list_4-8 0}ul.lst-kix_list_4-0{list-style-type:none}ul.lst-kix_list_4-1{list-style-type:none}ol.lst-kix_yyogjecm4su2-5.start{counter-reset:lst-ctn-kix_yyogjecm4su2-5 0}ul.lst-kix_list_4-4{list-style-type:none}.lst-kix_yyogjecm4su2-3>li{counter-increment:lst-ctn-kix_yyogjecm4su2-3}ul.lst-kix_list_4-5{list-style-type:none}ol.lst-kix_list_2-7{list-style-type:none}ul.lst-kix_list_4-2{list-style-type:none}.lst-kix_6vqbqdbyarbv-0>li:before{content:"" counter(lst-ctn-kix_6vqbqdbyarbv-0,decimal) ". "}ol.lst-kix_list_2-8{list-style-type:none}ul.lst-kix_list_4-3{list-style-type:none}ol.lst-kix_6vqbqdbyarbv-0{list-style-type:none}ol.lst-kix_6vqbqdbyarbv-1{list-style-type:none}ol.lst-kix_6vqbqdbyarbv-2{list-style-type:none}ol.lst-kix_6vqbqdbyarbv-3{list-style-type:none}ol.lst-kix_6vqbqdbyarbv-4{list-style-type:none}.lst-kix_list_2-8>li{counter-increment:lst-ctn-kix_list_2-8}ol.lst-kix_yyogjecm4su2-6.start{counter-reset:lst-ctn-kix_yyogjecm4su2-6 0}ol.lst-kix_6vqbqdbyarbv-5{list-style-type:none}ol.lst-kix_6vqbqdbyarbv-6{list-style-type:none}ol.lst-kix_list_4-7.start{counter-reset:lst-ctn-kix_list_4-7 0}.lst-kix_list_2-6>li:before{content:"   "}.lst-kix_list_2-7>li:before{content:" "}.lst-kix_list_2-7>li{counter-increment:lst-ctn-kix_list_2-7}.lst-kix_list_3-7>li{counter-increment:lst-ctn-kix_list_3-7}.lst-kix_list_2-4>li:before{content:"   "}.lst-kix_list_2-5>li:before{content:"   "}.lst-kix_list_2-8>li:before{content:" "}.lst-kix_6vqbqdbyarbv-7>li{counter-increment:lst-ctn-kix_6vqbqdbyarbv-7}ol.lst-kix_yyogjecm4su2-7.start{counter-reset:lst-ctn-kix_yyogjecm4su2-7 0}ul.lst-kix_list_3-1{list-style-type:none}ul.lst-kix_list_3-2{list-style-type:none}.lst-kix_yyogjecm4su2-6>li{counter-increment:lst-ctn-kix_yyogjecm4su2-6}ul.lst-kix_list_3-0{list-style-type:none}ol.lst-kix_list_1-7{list-style-type:none}ul.lst-kix_list_3-5{list-style-type:none}.lst-kix_list_4-7>li{counter-increment:lst-ctn-kix_list_4-7}.lst-kix_list_1-7>li{counter-increment:lst-ctn-kix_list_1-7}ol.lst-kix_list_1-8{list-style-type:none}ul.lst-kix_list_3-6{list-style-type:none}ol.lst-kix_list_3-8.start{counter-reset:lst-ctn-kix_list_3-8 0}.lst-kix_6vqbqdbyarbv-8>li{counter-increment:lst-ctn-kix_6vqbqdbyarbv-8}ul.lst-kix_list_3-3{list-style-type:none}ul.lst-kix_list_3-4{list-style-type:none}ol.lst-kix_yyogjecm4su2-4{list-style-type:none}.lst-kix_yyogjecm4su2-7>li:before{content:"" counter(lst-ctn-kix_yyogjecm4su2-0,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-1,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-2,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-3,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-4,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-5,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-6,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-7,decimal) ". "}ol.lst-kix_yyogjecm4su2-5{list-style-type:none}ol.lst-kix_yyogjecm4su2-2{list-style-type:none}.lst-kix_yyogjecm4su2-6>li:before{content:"" counter(lst-ctn-kix_yyogjecm4su2-0,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-1,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-2,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-3,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-4,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-5,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-6,decimal) ". "}.lst-kix_yyogjecm4su2-8>li:before{content:"" counter(lst-ctn-kix_yyogjecm4su2-0,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-1,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-2,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-3,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-4,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-5,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-6,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-7,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-8,decimal) ". "}ol.lst-kix_yyogjecm4su2-3{list-style-type:none}ol.lst-kix_yyogjecm4su2-0{list-style-type:none}.lst-kix_yyogjecm4su2-5>li:before{content:"" counter(lst-ctn-kix_yyogjecm4su2-0,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-1,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-2,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-3,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-4,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-5,decimal) ". "}ol.lst-kix_yyogjecm4su2-1{list-style-type:none}ol.lst-kix_6vqbqdbyarbv-3.start{counter-reset:lst-ctn-kix_6vqbqdbyarbv-3 0}ol.lst-kix_yyogjecm4su2-4.start{counter-reset:lst-ctn-kix_yyogjecm4su2-4 0}.lst-kix_list_4-0>li:before{content:"   "}.lst-kix_yyogjecm4su2-3>li:before{content:"" counter(lst-ctn-kix_yyogjecm4su2-0,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-1,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-2,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-3,decimal) ". "}.lst-kix_list_3-8>li{counter-increment:lst-ctn-kix_list_3-8}.lst-kix_list_4-1>li:before{content:"   "}.lst-kix_yyogjecm4su2-2>li:before{content:"" counter(lst-ctn-kix_yyogjecm4su2-0,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-1,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-2,decimal) ". "}.lst-kix_yyogjecm4su2-4>li:before{content:"" counter(lst-ctn-kix_yyogjecm4su2-0,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-1,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-2,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-3,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-4,decimal) ". "}ol.lst-kix_yyogjecm4su2-8{list-style-type:none}ol.lst-kix_yyogjecm4su2-6{list-style-type:none}ol.lst-kix_list_1-7.start{counter-reset:lst-ctn-kix_list_1-7 0}ol.lst-kix_yyogjecm4su2-7{list-style-type:none}.lst-kix_list_4-4>li:before{content:"   "}.lst-kix_yyogjecm4su2-5>li{counter-increment:lst-ctn-kix_yyogjecm4su2-5}.lst-kix_list_4-3>li:before{content:"   "}.lst-kix_list_4-5>li:before{content:"   "}.lst-kix_yyogjecm4su2-8>li{counter-increment:lst-ctn-kix_yyogjecm4su2-8}.lst-kix_list_4-2>li:before{content:"   "}.lst-kix_list_4-6>li:before{content:"   "}.lst-kix_6vqbqdbyarbv-6>li{counter-increment:lst-ctn-kix_6vqbqdbyarbv-6}.lst-kix_list_1-8>li{counter-increment:lst-ctn-kix_list_1-8}ol.lst-kix_6vqbqdbyarbv-6.start{counter-reset:lst-ctn-kix_6vqbqdbyarbv-6 0}ol.lst-kix_yyogjecm4su2-1.start{counter-reset:lst-ctn-kix_yyogjecm4su2-1 0}ol.lst-kix_yyogjecm4su2-8.start{counter-reset:lst-ctn-kix_yyogjecm4su2-8 0}ol.lst-kix_6vqbqdbyarbv-0.start{counter-reset:lst-ctn-kix_6vqbqdbyarbv-0 0}.lst-kix_yyogjecm4su2-0>li:before{content:"" counter(lst-ctn-kix_yyogjecm4su2-0,decimal) ". "}ol.lst-kix_list_2-8.start{counter-reset:lst-ctn-kix_list_2-8 0}.lst-kix_yyogjecm4su2-1>li:before{content:"" counter(lst-ctn-kix_yyogjecm4su2-0,decimal) "." counter(lst-ctn-kix_yyogjecm4su2-1,decimal) ". "}ol.lst-kix_list_4-8{list-style-type:none}ul.lst-kix_list_2-2{list-style-type:none}.lst-kix_list_1-0>li:before{content:"   "}ul.lst-kix_list_2-3{list-style-type:none}ul.lst-kix_list_2-0{list-style-type:none}ol.lst-kix_6vqbqdbyarbv-7.start{counter-reset:lst-ctn-kix_6vqbqdbyarbv-7 0}ul.lst-kix_list_2-1{list-style-type:none}ul.lst-kix_list_2-6{list-style-type:none}.lst-kix_list_1-1>li:before{content:"   "}.lst-kix_list_1-2>li:before{content:"   "}ul.lst-kix_list_2-4{list-style-type:none}ol.lst-kix_list_4-7{list-style-type:none}ul.lst-kix_list_2-5{list-style-type:none}ol.lst-kix_6vqbqdbyarbv-8.start{counter-reset:lst-ctn-kix_6vqbqdbyarbv-8 0}.lst-kix_list_1-3>li:before{content:"   "}.lst-kix_list_1-4>li:before{content:"   "}.lst-kix_6vqbqdbyarbv-2>li{counter-increment:lst-ctn-kix_6vqbqdbyarbv-2}.lst-kix_6vqbqdbyarbv-5>li{counter-increment:lst-ctn-kix_6vqbqdbyarbv-5}ol.lst-kix_6vqbqdbyarbv-1.start{counter-reset:lst-ctn-kix_6vqbqdbyarbv-1 0}.lst-kix_yyogjecm4su2-1>li{counter-increment:lst-ctn-kix_yyogjecm4su2-1}ol.lst-kix_yyogjecm4su2-2.start{counter-reset:lst-ctn-kix_yyogjecm4su2-2 0}.lst-kix_list_4-8>li{counter-increment:lst-ctn-kix_list_4-8}.lst-kix_list_1-7>li:before{content:" "}ol.lst-kix_list_2-7.start{counter-reset:lst-ctn-kix_list_2-7 0}.lst-kix_yyogjecm4su2-4>li{counter-increment:lst-ctn-kix_yyogjecm4su2-4}.lst-kix_yyogjecm4su2-7>li{counter-increment:lst-ctn-kix_yyogjecm4su2-7}.lst-kix_list_1-5>li:before{content:"   "}.lst-kix_list_1-6>li:before{content:"   "}.lst-kix_list_2-0>li:before{content:"   "}.lst-kix_list_2-1>li:before{content:"   "}.lst-kix_list_1-8>li:before{content:" "}.lst-kix_list_2-2>li:before{content:"   "}.lst-kix_list_2-3>li:before{content:"   "}ol{margin:0;padding:0}table td,table th{padding:0}.c41{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#cccccc;border-left-style:solid;border-bottom-width:1pt;width:152.2pt;border-top-color:#000000;border-bottom-style:solid}.c21{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:78.8pt;border-top-color:#000000;border-bottom-style:solid}.c56{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:191.2pt;border-top-color:#000000;border-bottom-style:solid}.c69{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:468pt;border-top-color:#000000;border-bottom-style:solid}.c52{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:103.5pt;border-top-color:#000000;border-bottom-style:solid}.c57{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:147pt;border-top-color:#000000;border-bottom-style:solid}.c2{background-color:#f8f8f8;color:#4e9a06;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Consolas";font-style:italic}.c20{padding-top:9pt;text-indent:36pt;padding-bottom:9pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Consolas";font-style:italic}.c3{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c4{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Cambria";font-style:normal}.c0{padding-top:0pt;padding-bottom:5pt;line-height:1.0;orphans:2;widows:2;text-align:left;height:12pt}.c61{padding-top:12pt;padding-bottom:0pt;line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c15{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:center}.c66{padding-top:0pt;padding-bottom:10pt;line-height:2.0;orphans:2;widows:2;text-align:left}.c42{padding-top:9pt;padding-bottom:9pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c44{padding-top:9pt;padding-bottom:9pt;line-height:1.15;page-break-after:avoid;text-align:left;height:14pt}.c45{padding-top:0pt;padding-bottom:10pt;line-height:1.0;orphans:2;widows:2;text-align:center}.c14{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:justify}.c78{padding-top:0pt;padding-bottom:10pt;line-height:1.0;orphans:2;widows:2;text-align:right}.c22{padding-top:0pt;padding-bottom:10pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c36{padding-top:0pt;padding-bottom:10pt;line-height:2.0;orphans:2;widows:2;text-align:center}.c17{padding-top:9pt;padding-bottom:9pt;line-height:1.0;orphans:2;widows:2;text-align:center}.c64{padding-top:0pt;padding-bottom:10pt;line-height:1.0909090909090908;orphans:2;widows:2;text-align:center}.c43{padding-top:24pt;padding-bottom:0pt;line-height:1.15;page-break-after:avoid;text-align:left}.c1{background-color:#f8f8f8;font-size:8pt;font-family:"Consolas";color:#204a87;font-weight:700}.c24{color:#000000;text-decoration:none;vertical-align:baseline;font-size:10pt;font-style:normal}.c72{padding-top:24pt;padding-bottom:0pt;line-height:2.0;page-break-after:avoid;text-align:center}.c7{background-color:#f8f8f8;font-size:8pt;font-family:"Consolas";color:#4e9a06;font-weight:400}.c51{padding-top:9pt;padding-bottom:9pt;line-height:1.15;page-break-after:avoid;text-align:left}.c27{color:#000000;text-decoration:none;vertical-align:baseline;font-size:16pt;font-style:normal}.c8{background-color:#f8f8f8;font-size:8pt;font-family:"Consolas";color:#000000;font-weight:400}.c6{background-color:#f8f8f8;font-size:8pt;font-family:"Consolas";color:#0000cf;font-weight:400}.c19{font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Cambria";font-style:normal}.c40{padding-top:10pt;padding-bottom:0pt;line-height:1.15;page-break-after:avoid;text-align:left}.c26{color:#000000;text-decoration:none;vertical-align:baseline;font-size:12pt;font-style:normal}.c77{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c70{-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline;text-decoration-skip-ink:none}.c58{border-spacing:0;border-collapse:collapse;margin-right:auto}.c74{margin-left:86.2pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c49{margin-left:auto;border-spacing:0;border-collapse:collapse;margin-right:auto}.c37{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:center}.c18{color:#ce5c00;font-weight:700;font-size:8pt;font-family:"Consolas"}.c35{color:#4f81bd;font-weight:700;font-size:16pt;font-family:"Calibri"}.c76{color:#335b8a;font-weight:700;font-family:"Calibri"}.c16{text-decoration:none;vertical-align:baseline;font-style:italic}.c50{color:#4f81bd;font-weight:700;font-family:"Calibri"}.c32{text-decoration:none;vertical-align:baseline;font-style:normal}.c11{background-color:#f8f8f8;font-size:8pt;color:#204a87}.c53{color:#366091;font-weight:400;font-family:"Calibri"}.c71{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c9{color:#000000;font-size:8pt}.c54{margin-left:36pt;padding-left:0pt}.c60{margin-left:72pt;padding-left:0pt}.c23{font-weight:400;font-family:"Times New Roman"}.c38{padding:0;margin:0}.c62{color:inherit;text-decoration:inherit}.c10{font-family:"Consolas";font-weight:400}.c55{margin-left:108pt;padding-left:0pt}.c25{margin-left:108pt;height:12pt}.c12{font-weight:700;font-family:"Times New Roman"}.c31{text-indent:36pt}.c47{height:21pt}.c65{background-color:#cccccc}.c39{height:12pt}.c30{font-size:8pt}.c29{font-style:italic}.c59{height:16pt}.c33{height:0pt}.c46{font-size:14pt}.c13{background-color:#f8f8f8}.c48{font-size:16pt}.c73{font-size:11pt}.c75{font-size:13pt}.c67{margin-left:72pt}.c63{font-size:6pt}.c28{color:#000000}.c34{color:#8f5902}.c68{height:15pt}.c79{font-size:12pt}.title{padding-top:24pt;color:#335b8a;font-weight:700;font-size:18pt;padding-bottom:12pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:center}.subtitle{padding-top:12pt;color:#335b8a;font-weight:700;font-size:15pt;padding-bottom:12pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:center}li{color:#000000;font-size:12pt;font-family:"Cambria"}p{margin:0;color:#000000;font-size:12pt;font-family:"Cambria"}h1{padding-top:24pt;color:#335b8a;font-weight:700;font-size:16pt;padding-bottom:0pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:10pt;color:#4f81bd;font-weight:700;font-size:16pt;padding-bottom:0pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:10pt;color:#4f81bd;font-weight:700;font-size:14pt;padding-bottom:0pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:10pt;color:#4f81bd;font-weight:700;font-size:12pt;padding-bottom:0pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:10pt;color:#4f81bd;font-size:12pt;padding-bottom:0pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#4f81bd;font-size:12pt;padding-bottom:0pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c71"><p class="c36"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 269.00px; height: 256.66px;"><img alt="" src="images/image19.png" style="width: 269.00px; height: 256.66px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c45 c39"><span class="c27 c12"></span></p><p class="c45 c39"><span class="c27 c12"></span></p><p class="c45 c39"><span class="c27 c12"></span></p><p class="c45 c39"><span class="c27 c12"></span></p><p class="c39 c45"><span class="c27 c12"></span></p><p class="c45 c39"><span class="c27 c12"></span></p><p class="c45"><span class="c12 c48">Final Project Report</span></p><a id="t.f1cfcc280423010a2728f8710ba36234e62bc87e"></a><a id="t.0"></a><table class="c49"><tbody><tr class="c33"><td class="c69" colspan="1" rowspan="1"><p class="c37"><span class="c23 c27">Multilevel Bayesian Model for U.S. Labor Force Participation Rate</span></p></td></tr></tbody></table><p class="c66 c39"><span class="c32 c23 c63 c28"></span></p><a id="t.d148b069ed2b48a3f65211efc995092c176a3a0a"></a><a id="t.1"></a><table class="c49"><tbody><tr class="c33"><td class="c52" colspan="1" rowspan="1"><p class="c77"><span class="c3">Course Code</span></p></td><td class="c56" colspan="1" rowspan="1"><p class="c37"><span class="c26 c23">STAT 5224 GR</span></p></td></tr><tr class="c33"><td class="c52" colspan="1" rowspan="1"><p class="c77"><span class="c3">Course Title</span></p></td><td class="c56" colspan="1" rowspan="1"><p class="c37"><span class="c26 c23">Bayesian Statistics</span></p></td></tr><tr class="c33"><td class="c52" colspan="1" rowspan="1"><p class="c77"><span class="c3">Instructor</span></p></td><td class="c56" colspan="1" rowspan="1"><p class="c37"><span class="c26 c23">Andrew Gelman</span></p></td></tr></tbody></table><p class="c66 c39"><span class="c32 c23 c63 c28"></span></p><a id="t.4b28d695d2925051692b627b3e94416fe2849001"></a><a id="t.2"></a><table class="c74"><tbody><tr class="c47"><td class="c57" colspan="1" rowspan="1"><p class="c64"><span class="c12">Member Name</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c64"><span class="c12">UNI</span></p></td></tr><tr class="c68"><td class="c57" colspan="1" rowspan="1"><p class="c37"><span class="c26 c23">Fan, Yang</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c37"><span class="c26 c23">fy2230</span></p></td></tr><tr class="c68"><td class="c57" colspan="1" rowspan="1"><p class="c37"><span class="c26 c23">Xiaotong, Li</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c37"><span class="c26 c23">xl2788</span></p></td></tr><tr class="c68"><td class="c57" colspan="1" rowspan="1"><p class="c37"><span class="c26 c23">Xiaotong, Lin</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c37"><span class="c26 c23">xl2506</span></p></td></tr></tbody></table><p class="c66 c39"><span class="c4"></span></p><p class="c66"><span class="c4">Submission Date: December 9, 2018</span></p><h1 class="c72" id="h.72skbol6ppth"><span class="c27 c12">Table of Content</span></h1><ol class="c38 lst-kix_6vqbqdbyarbv-0 start" start="1"><li class="c22 c54"><span class="c32 c12 c46 c28">Introduction</span></li></ol><ol class="c38 lst-kix_6vqbqdbyarbv-1 start" start="1"><li class="c22 c60"><span class="c3">Data Example&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li></ol><p class="c22 c39"><span class="c3"></span></p><ol class="c38 lst-kix_6vqbqdbyarbv-0" start="2"><li class="c22 c54"><span class="c32 c12 c46 c28">Multilevel Logistic Regression Model</span></li></ol><ol class="c38 lst-kix_6vqbqdbyarbv-1 start" start="1"><li class="c22 c60"><span class="c3">Fitting Logit Regression On Multiple Predictors</span></li></ol><ol class="c38 lst-kix_6vqbqdbyarbv-2 start" start="1"><li class="c22 c55"><span class="c26 c23">Model Formulation</span></li><li class="c22 c55"><span class="c26 c23">Model Checking</span></li></ol><p class="c22 c25"><span class="c32 c23 c63 c28"></span></p><ol class="c38 lst-kix_6vqbqdbyarbv-1" start="2"><li class="c22 c60"><span class="c3">Model Fitting for Each State</span></li></ol><ol class="c38 lst-kix_6vqbqdbyarbv-2 start" start="1"><li class="c22 c55"><span class="c26 c23">Model Checking and Summary</span></li><li class="c22 c55"><span class="c26 c23">Model Evaluation</span></li></ol><p class="c22 c25"><span class="c32 c23 c63 c28"></span></p><ol class="c38 lst-kix_6vqbqdbyarbv-1" start="3"><li class="c22 c60"><span class="c3">A Vectorization Version of the Multi-Logit Regression Model</span></li></ol><p class="c22 c39"><span class="c32 c12 c46 c28"></span></p><ol class="c38 lst-kix_6vqbqdbyarbv-0" start="3"><li class="c22 c54"><span class="c32 c12 c46 c28">Potential Model Expansion</span></li></ol><ol class="c38 lst-kix_6vqbqdbyarbv-1 start" start="1"><li class="c22 c60"><span class="c3">Varying Intercept Model with No Predictors</span></li></ol><ol class="c38 lst-kix_6vqbqdbyarbv-2 start" start="1"><li class="c22 c55"><span class="c26 c23">Labor Force Participation Rate based on State</span></li><li class="c22 c55"><span class="c26 c23">Labor Force Participation Rate based on Income</span></li></ol><p class="c22 c25"><span class="c32 c12 c63 c28"></span></p><ol class="c38 lst-kix_6vqbqdbyarbv-1" start="2"><li class="c22 c60"><span class="c3">Varying intercept Model with a Single Predictor</span></li></ol><p class="c22 c39 c67"><span class="c32 c12 c28 c63"></span></p><ol class="c38 lst-kix_6vqbqdbyarbv-1" start="3"><li class="c22 c60"><span class="c3">Varying Intercept and Slope Model with a Single Predictor</span></li></ol><p class="c22 c39"><span class="c26 c23"></span></p><ol class="c38 lst-kix_6vqbqdbyarbv-0" start="4"><li class="c22 c54"><span class="c32 c12 c46 c28">Conclusion</span></li></ol><p class="c39 c61"><span class="c32 c48 c53"></span></p><p class="c0"><span class="c4"></span></p><p class="c0"><span class="c4"></span></p><a id="id.gjdgxs"></a><h1 class="c43" id="h.30j0zll"><span class="c23 c28">1. Introduction</span></h1><p class="c22 c31"><span class="c26 c23">Labor force participation rate, defined as the inverse of the unemployment rate, is the percentage of working people in a group of people who are currently available for work. Rising labor force participation rate is seen as a sign of &nbsp;strong economy, with fast growth and great spending. The determination of the health of the economy also helps to set monetary policy.</span></p><p class="c22 c31"><span class="c23">To gain more insights about U.S labor force participation rate, our group looks for the </span><span class="c70 c23"><a class="c62" href="https://www.google.com/url?q=https://cps.ipums.org/cps/&amp;sa=D&amp;ust=1544399673441000">U.S. Current Population Survey</a></span><span class="c23">&nbsp;</span><span class="c26 c23">from 1976 to 2015 providing individual-level data on geographic and demographic characteristics, including sex, race, age, skill, annual income, state, year, and labor market outcomes. </span></p><p class="c22 c31"><span class="c23">As we set each variable affecting the U.S. labor force participation rate into different groups, multinomial logistic regression, which is a classification method that generalizes logistic regression to multiclass problems, seems to be a good fit to </span><span class="c23">our data</span><span class="c26 c23">set with categorically distributed dependent variables to predict whether a person participates in a job or not. </span></p><p class="c22 c31"><span class="c23">This project will use R version 3.5.0 and Stan version 2.17.3. It also requires the following R packages:</span></p><p class="c22"><span class="c1 c29">library</span><span class="c10 c30 c29 c13">(rtan)</span><span class="c10 c30 c29"><br></span><span class="c1 c29">library</span><span class="c10 c30 c29 c13">(lme4)</span><span class="c10 c30 c29"><br></span><span class="c1 c29">library</span><span class="c10 c30 c29 c13">(rstanarm)</span><span class="c10 c30 c29"><br></span><span class="c1 c29">library</span><span class="c10 c30 c29 c13">(gridExtra)</span><span class="c10 c30 c29"><br></span><span class="c1 c29">library</span><span class="c10 c30 c29 c13">(ggplot2)</span><span class="c10 c30 c29"><br></span><span class="c1 c29">library</span><span class="c5 c13">(lattice)</span></p><h2 class="c40 c59" id="h.qr1dpo4qh3z2"><span class="c32 c12 c46 c28"></span></h2><h2 class="c40" id="h.e939lc9jpcsy"><span class="c23 c46 c28">1.1 Data Example</span></h2><p class="c22"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c23">We will analyze the </span><span class="c23 c70"><a class="c62" href="https://www.google.com/url?q=https://cps.ipums.org/cps/&amp;sa=D&amp;ust=1544399673443000">U.S. Current Population Survey</a></span><span class="c23">&nbsp;</span><span class="c26 c23">from 5,219,430 respondents by grouping total 8 variables as follows:</span></p><a id="t.4b23a8b9d7f4dcddc66ab2ec859f2a8f9ec9a5c4"></a><a id="t.3"></a><table class="c58"><tbody><tr class="c33"><td class="c41" colspan="1" rowspan="1"><p class="c15"><span class="c24 c12">Variable</span></p></td><td class="c21 c65" colspan="1" rowspan="1"><p class="c15"><span class="c24 c12">Group #1</span></p></td><td class="c21 c65" colspan="1" rowspan="1"><p class="c15"><span class="c24 c12">Group #2</span></p></td><td class="c21 c65" colspan="1" rowspan="1"><p class="c15"><span class="c24 c12">Group #3</span></p></td><td class="c21 c65" colspan="1" rowspan="1"><p class="c15"><span class="c24 c12">Group #4</span></p></td></tr><tr class="c33"><td class="c41" colspan="1" rowspan="1"><p class="c15"><span class="c24 c12">sex</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">Male</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">Female</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">NA</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">NA</span></p></td></tr><tr class="c33"><td class="c41" colspan="1" rowspan="1"><p class="c15"><span class="c24 c12">race</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">white</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">not-white</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">NA</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">NA</span></p></td></tr><tr class="c33"><td class="c41" colspan="1" rowspan="1"><p class="c15"><span class="c24 c12">age</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">20-29</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">30-39</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">40-49</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">50-59</span></p></td></tr><tr class="c33"><td class="c41" colspan="1" rowspan="1"><p class="c15"><span class="c24 c12">skill</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">skilled</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">not-skilled</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">NA</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">NA</span></p></td></tr><tr class="c33"><td class="c41" colspan="1" rowspan="1"><p class="c15"><span class="c24 c12">annual income</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">0-40k</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">40k-100k</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">100k-200k</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">&gt;200k</span></p></td></tr><tr class="c33"><td class="c41" colspan="1" rowspan="1"><p class="c15"><span class="c12 c24">state</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">north-west</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">south-west</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">north-east</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">south-east</span></p></td></tr><tr class="c33"><td class="c41" colspan="1" rowspan="1"><p class="c15"><span class="c24 c12">year</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">1976-1985</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">1986-1995</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">1996-2005</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">2006-2015</span></p></td></tr><tr class="c33"><td class="c41" colspan="1" rowspan="1"><p class="c15"><span class="c24 c12">labor force participation</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">unemployed</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">employed</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">NA</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c15"><span class="c24 c23">NA</span></p></td></tr></tbody></table><p class="c22"><span class="c26 c23">Then the dataset consists of variables:</span></p><p class="c22"><span class="c8 c32">&gt; summary(wage)<br> &nbsp; &nbsp; sex &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; race &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; age &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;skilled &nbsp; &nbsp;<br> Min. &nbsp; :1.000 &nbsp; Min. &nbsp; :0.0000 &nbsp; Min. &nbsp; :0.000 &nbsp; Min. &nbsp; :0.0000 &nbsp;<br> 1st Qu.:1.000 &nbsp; 1st Qu.:1.0000 &nbsp; 1st Qu.:1.000 &nbsp; 1st Qu.:0.0000<br> Median :2.000 &nbsp; Median :1.0000 &nbsp; Median :1.000 &nbsp; Median :0.0000<br> Mean &nbsp; :1.528 &nbsp; Mean &nbsp; :0.8375 &nbsp; Mean &nbsp; :1.374 &nbsp; Mean &nbsp; :0.4243 &nbsp;<br> 3rd Qu.:41.00 &nbsp; 3rd Qu.:1.0000 &nbsp; 3rd Qu.:2.000 &nbsp; 3rd Qu.:1.0000<br> Max. &nbsp; :2.000 &nbsp; Max. &nbsp; :3.000 &nbsp; &nbsp;Max. &nbsp; :1.0000 &nbsp;Max. &nbsp; :170.000 &nbsp;<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; &nbsp; income &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;state &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;year &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; lfp &nbsp; &nbsp; &nbsp; &nbsp;<br> Min. &nbsp; : &nbsp;0.000 Min. &nbsp; : 1.00 &nbsp; &nbsp;Min. &nbsp; :1976 &nbsp; &nbsp;Min. &nbsp; :0.0000 &nbsp;<br> 1st Qu.: &nbsp;0.000 1st Qu.:13.00 &nbsp; &nbsp;1st Qu.:1987 &nbsp; &nbsp;1st Qu.:0.0000 &nbsp;<br> Median : &nbsp;1.000 Median :29.00 &nbsp; &nbsp;Median :1998 &nbsp; &nbsp;Median :1.0000 &nbsp;<br> Mean &nbsp; : &nbsp;1.738 Mean &nbsp; :28.02 &nbsp; &nbsp;Mean &nbsp; :1997 &nbsp; &nbsp;Mean &nbsp; :0.6428 &nbsp;<br> 3rd Qu.: &nbsp;2.000 3rd Qu.:2.000 &nbsp; &nbsp;3rd Qu.:2007 &nbsp; &nbsp;3rd Qu.:1.0000 &nbsp;<br> Max. &nbsp; :1.0000 &nbsp;Max. &nbsp; :56.00 &nbsp; &nbsp;Max. &nbsp; :2015 &nbsp; &nbsp;Max. &nbsp; :1.0000</span></p><p class="c22 c39"><span class="c32 c9 c23"></span></p><p class="c22 c31"><span class="c26 c23">By grouping people with specific variable, such as state and income, we can also calculate their labor force participation rate by the total number of people in the group dividing the number of people who work and generate distinct datasets as follows: </span></p><p class="c22"><span class="c1">head</span><span class="c8 c32">(state)</span></p><p class="c22"><span class="c9 c10">## &nbsp; year state lfpr</span><span class="c9"><br></span><span class="c9 c10">## 1 1977 &nbsp; &nbsp; 1 0.55</span><span class="c9"><br></span><span class="c9 c10">## 2 1978 &nbsp; &nbsp; 1 0.54</span><span class="c9"><br></span><span class="c9 c10">## 3 1979 &nbsp; &nbsp; 1 0.54</span><span class="c9"><br></span><span class="c9 c10">## 4 1980 &nbsp; &nbsp; 1 0.55</span><span class="c9"><br></span><span class="c9 c10">## 5 1981 &nbsp; &nbsp; 1 0.56</span><span class="c9"><br></span><span class="c9 c10">## 6 1982 &nbsp; &nbsp; 1 0.56</span></p><p class="c22"><span class="c1">ggplot</span><span class="c8">(state, </span><span class="c1">aes</span><span class="c8">(</span><span class="c11 c10">x=</span><span class="c8">state,</span><span class="c11 c10">y=</span><span class="c8">lfpr)) </span><span class="c18 c13">+</span><span class="c7">&nbsp;</span><span class="c1">geom_smooth</span><span class="c8">() </span><span class="c18 c13">+</span><span class="c7">&nbsp;</span><span class="c1">labs</span><span class="c8">(</span><span class="c11 c10">y=</span><span class="c7">&#39;lfp rate&#39;</span><span class="c8">)</span></p><p class="c22"><span class="c9 c10">## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39;</span></p><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 469.00px; height: 284.15px;"><img alt="" src="images/image34.jpg" style="width: 469.00px; height: 284.15px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c17"><span class="c32 c9 c23">Fig.1.1.1: Labor Force Participation Rate of States</span></p><p class="c22 c31"><span class="c26 c23">From above grouping by state, we can see that Minnesota has the greatest labor force participation rate. On the other hand, Alabama has the lowest labor force participation rate.<br></span></p><p class="c22"><span class="c10 c30">head(income)<br>## &nbsp; year &nbsp;income lfpr<br>## 1 1976 &nbsp; &nbsp; &nbsp;0 0.37<br>## 2 1977 &nbsp; &nbsp; &nbsp;0 0.39<br>## 3 1978 &nbsp; &nbsp; &nbsp;0 0.38<br>## 4 1979 &nbsp; &nbsp; &nbsp;0 0.38<br>## 5 1980 &nbsp; &nbsp; &nbsp;0 0.38<br>## 6 1981 &nbsp; &nbsp; &nbsp;0 0.37<br> <br>ggplot(income, aes(x=income,y=lfpr)) + geom_smooth() + labs(y=&#39;lfp rate&#39;)<br>## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39;<br></span></p><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 421.66px; height: 270.50px;"><img alt="" src="images/image22.jpg" style="width: 421.66px; height: 270.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c17"><span class="c32 c9 c23">Fig.1.1.2: Labor Force Participation Rate of Income Group</span></p><p class="c22 c31 c39"><span class="c26 c23"></span></p><p class="c22 c31"><span class="c23">From above grouping by income, we can see that annual income has a positive relationship with labor force participation rate before it reaches $100,000. Afterwards, labor force participation rate keeps fluctuating horizontally with the increase of annual income. In addition, when people&rsquo;s annual income is larger than 1,500k, their labor force participation rate fluctuates a lot.</span></p><p class="c20 c39"><span class="c4"></span></p><p class="c42 c39"><span class="c4"></span></p><p class="c42 c39"><span class="c4"></span></p><a id="id.1fob9te"></a><h1 class="c43" id="h.3znysh7"><span class="c27 c12">2. Multilevel Logistic Regression Model</span></h1><h2 class="c40" id="h.2et92p0"><span class="c23 c46 c28">2.1 Fitting Logit Regression On Multiple Predictors</span></h2><h3 class="c40" id="h.l818fr573p7e"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c23 c28 c75">2.1.1 Model Formulation</span></h3><p class="c22"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c26 c23">When attempting to fit models to the labor force participation, the logistic regression model seems to be a suitable choice considered that the labor participation is primarily a binary data filled with 0 and 1. &nbsp;In the discussion of Regression model in Stan User&rsquo;s Guide book, it provides a hint on fitting a simple logistic models on one predictor. This model is formulated by logit-parameterized version of the Bernoulli distribution which is defined as: </span></p><p class="c45"><img><span class="c23">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><img src="images/image1.png"></p><p class="c22"><span class="c26 c23">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;From the Stan book, we learned that the error is built into the Stan, therefore we do not bother to account for that specifically. When attempting to fit the model to multiple predictors, we build our model in a format similar to the single predictor logit regression model:</span></p><p class="c45"><img src="images/image2.png"><span class="c23">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><img></p><p class="c22"><span class="c26 c23">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;To explain this model, we consider k = 7 predictors which include sex, age, race, skill, annual income, state and year as we have discussed in the introduction section where we have explained the grouping criterion in details. This is by far the most comprehensive models that specifically examine each coefficients on the predictors to avoid identifiability issue when using matrix as predictor inputs (vectorization). However, this model may cause scalability issue and sacrifice efficiency due to unreasonably long run-time in computation. So, the following stan model is not suggested if used in a large dataset. In our case, we also realize this problem and draw random samples of 15,000 from the dataset to make our model run faster. We separate the sample data into 5 fold with 3,000 in each fold. Then we use random 4 folds as training set and the last one as test set to compute prediction rate of the model. This will yield potentials for out-of-sample predictions when it comes to the model evaluation. We will come back to this after the results.</span></p><p class="c22"><span class="c26 c23">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;But on the good side, this model provides us a better insight on the intercept and the coefficients. By manipulating the model from the snippet of the simple logit regression, we add a transformed model block to see the normalized coefficients and the error scale for each predictor. We impose a weak prior on each of the parameters because no particular prior knowledge of these parameters are assumed. </span></p><p class="c22"><span class="c26 c23">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;It is worthwhile to mention that, in this model, we generate the prediction in the stan model rather than make prediction in R. Also, since we want the out-of-sample prediction, the model reads from the test data set for later prediction. This fit-and-predict method is slow yet fairly accurate, which is highly suggested in the Stan book, so we borrow this idea and incorporate this part in our model. However, for faster computation, we suggest to predict outside of Stan, such as making direct prediction by using the estimation results from Stan. Quite a trade-off between efficiency and accuracy!</span></p><p class="c22 c39"><span class="c26 c23"></span></p><p class="c22"><span class="c10 c30 c29 c13">##############################################Stan Code###################################################<br>data {<br> &nbsp;int N;<br> &nbsp;int Nt;<br> &nbsp;int x1_N; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// &nbsp;number of categories in x1<br> &nbsp;int x2_N; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// &nbsp;number of categories in x2<br> &nbsp;int x3_N; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// &nbsp;number of categories in x3<br> &nbsp;int x4_N; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// &nbsp;number of categories in x4<br> &nbsp;int x5_N; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// &nbsp;number of categories in x5<br> &nbsp;int x6_N; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// &nbsp;number of categories in x6<br> &nbsp;int x7_N; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// &nbsp;number of categories in x7<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp;int&lt;lower=1, upper=x1_N&gt; x1[N];<br> &nbsp;int&lt;lower=1, upper=x2_N&gt; x2[N];<br> &nbsp;int&lt;lower=1, upper=x3_N&gt; x3[N];<br> &nbsp;int&lt;lower=1, upper=x4_N&gt; x4[N];<br> &nbsp;int&lt;lower=1, upper=x5_N&gt; x5[N];<br> &nbsp;int&lt;lower=1, upper=x6_N&gt; x6[N];<br> &nbsp;int&lt;lower=1, upper=x7_N&gt; x7[N];<br> &nbsp;<br> &nbsp;int&lt;lower=1, upper=x1_N&gt; x1t[Nt];<br> &nbsp;int&lt;lower=1, upper=x2_N&gt; x2t[Nt];<br> &nbsp;int&lt;lower=1, upper=x3_N&gt; x3t[Nt];<br> &nbsp;int&lt;lower=1, upper=x4_N&gt; x4t[Nt];<br> &nbsp;int&lt;lower=1, upper=x5_N&gt; x5t[Nt];<br> &nbsp;int&lt;lower=1, upper=x6_N&gt; x6t[Nt];<br> &nbsp;int&lt;lower=1, upper=x7_N&gt; x7t[Nt];<br> &nbsp;int&lt;lower=0, upper=1&gt; y[N];<br>}<br>parameters {<br> &nbsp;real intercept;<br> &nbsp;vector[x1_N] x1_coeff;<br> &nbsp;vector[x2_N] x2_coeff;<br> &nbsp;vector[x3_N] x3_coeff;<br> &nbsp;vector[x4_N] x4_coeff;<br> &nbsp;vector[x5_N] x5_coeff;<br> &nbsp;vector[x6_N] x6_coeff;<br> &nbsp;vector[x7_N] x7_coeff;<br> &nbsp;real&lt;lower=0&gt; sigma_x1;<br> &nbsp;real&lt;lower=0&gt; sigma_x2;<br> &nbsp;real&lt;lower=0&gt; sigma_x3;<br> &nbsp;real&lt;lower=0&gt; sigma_x4;<br> &nbsp;real&lt;lower=0&gt; sigma_x5;<br> &nbsp;real&lt;lower=0&gt; sigma_x6;<br> &nbsp;real&lt;lower=0&gt; sigma_x7;<br>}<br>transformed parameters {<br> &nbsp;vector[x1_N] normalized_x1_coeff;<br> &nbsp;vector[x2_N] normalized_x2_coeff;<br> &nbsp;vector[x3_N] normalized_x3_coeff;<br> &nbsp;vector[x4_N] normalized_x4_coeff;<br> &nbsp;vector[x5_N] normalized_x5_coeff;<br> &nbsp;vector[x6_N] normalized_x6_coeff;<br> &nbsp;vector[x7_N] normalized_x7_coeff;<br> &nbsp;normalized_x1_coeff = x1_coeff - x1_coeff[1];<br> &nbsp;normalized_x2_coeff = x2_coeff - x2_coeff[1];<br> &nbsp;normalized_x3_coeff = x3_coeff - x3_coeff[1];<br> &nbsp;normalized_x4_coeff = x4_coeff - x4_coeff[1];<br> &nbsp;normalized_x5_coeff = x5_coeff - x5_coeff[1];<br> &nbsp;normalized_x6_coeff = x6_coeff - x6_coeff[1];<br> &nbsp;normalized_x7_coeff = x7_coeff - x7_coeff[1];<br>}<br>model {<br> &nbsp;vector[N] p; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// probabilities<br> &nbsp;// priors<br> &nbsp;intercept ~ normal(0, 20);<br> &nbsp;sigma_x1 ~ cauchy(0, 5);<br> &nbsp;sigma_x2 ~ cauchy(0, 5);<br> &nbsp;sigma_x3 ~ cauchy(0, 5);<br> &nbsp;sigma_x4 ~ cauchy(0, 5);<br> &nbsp;sigma_x5 ~ cauchy(0, 5);<br> &nbsp;sigma_x6 ~ cauchy(0, 5);<br> &nbsp;sigma_x7 ~ cauchy(0, 5);<br> &nbsp;// level 1<br> &nbsp;x1_coeff ~ normal(0, sigma_x1);<br> &nbsp;x2_coeff ~ normal(0, sigma_x2);<br> &nbsp;x3_coeff ~ normal(0, sigma_x3);<br> &nbsp;x4_coeff ~ normal(0, sigma_x4);<br> &nbsp;x5_coeff ~ normal(0, sigma_x5);<br> &nbsp;x6_coeff ~ normal(0, sigma_x6);<br> &nbsp;x7_coeff ~ normal(0, sigma_x7);<br> &nbsp;// level 2<br> &nbsp;for (i in 1:N) {<br> &nbsp; &nbsp;p[i] &lt;- x1_coeff[x1[i]] + x2_coeff[x2[i]] + x3_coeff[x3[i]] + x4_coeff[x4[i]]+ &nbsp;x5_coeff[x5[i]]+ &nbsp;x6_coeff[x6[i]]+ x7_coeff[x7[i]]; &nbsp; <br>}<br> &nbsp;y ~ bernoulli_logit(intercept + p);<br>}<br>generated quantities{<br> &nbsp;vector[Nt] y_test;<br> &nbsp;vector[Nt] pt;<br> &nbsp;for (i in 1:Nt) {<br> &nbsp; &nbsp;pt[i] &lt;- x1_coeff[x1t[i]] + x2_coeff[x2t[i]] + x3_coeff[x3t[i]] + x4_coeff[x4t[i]]+ &nbsp;x5_coeff[x5t[i]]+ &nbsp;x6_coeff[x6t[i]]+ &nbsp;x7_coeff[x7t[i]];<br> &nbsp; &nbsp;y_test[i] = bernoulli_rng(inv_logit(intercept + pt[i]));<br> &nbsp;}}</span><span class="c1 c16"><br></span></p><p class="c22"><span class="c5">#############################################Implement Stan###############################################</span></p><p class="c22"><span class="c1 c16">rstan_options</span><span class="c5 c13">(</span><span class="c16 c11 c10">auto_write=</span><span class="c16 c10 c30 c13 c34">TRUE</span><span class="c5 c13">)</span><span class="c5"><br></span><span class="c1 c16">options</span><span class="c5 c13">(</span><span class="c16 c11 c10">mc.cores =</span><span class="c5 c13">&nbsp;parallel</span><span class="c18 c16 c13">::</span><span class="c1 c16">detectCores</span><span class="c5 c13">())</span><span class="c5"><br></span><span class="c5 c13">wage &lt;-</span><span class="c2">&nbsp;</span><span class="c1 c16">read.csv</span><span class="c5 c13">(</span><span class="c2">&quot;lfp.csv&quot;</span><span class="c5 c13">)</span><span class="c5"><br></span><span class="c5 c13">wage&lt;-</span><span class="c2">&nbsp;</span><span class="c1 c16">as.data.frame</span><span class="c5 c13">(wage)</span><span class="c5"><br><br></span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">income[</span><span class="c1 c16">which</span><span class="c5 c13">(wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">income</span><span class="c18 c16 c13">&lt;=</span><span class="c6 c16">4</span><span class="c5 c13">)] &lt;-</span><span class="c2">&nbsp;</span><span class="c6 c16">1</span><span class="c5"><br></span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">income[</span><span class="c1 c16">which</span><span class="c5 c13">(wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">income</span><span class="c18 c16 c13">&gt;</span><span class="c6 c16">4</span><span class="c5 c13">&nbsp;</span><span class="c18 c16 c13">&amp;</span><span class="c2">&nbsp;</span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">income</span><span class="c18 c16 c13">&lt;=</span><span class="c6 c16">10</span><span class="c5 c13">)] &lt;-</span><span class="c2">&nbsp;</span><span class="c6 c16">2</span><span class="c5"><br></span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">income[</span><span class="c1 c16">which</span><span class="c5 c13">(wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">income</span><span class="c18 c16 c13">&gt;</span><span class="c6 c16">10</span><span class="c5 c13">&nbsp;</span><span class="c18 c16 c13">&amp;</span><span class="c2">&nbsp;</span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">income</span><span class="c18 c16 c13">&lt;=</span><span class="c6 c16">20</span><span class="c5 c13">)] &lt;-</span><span class="c2">&nbsp;</span><span class="c6 c16">3</span><span class="c5"><br></span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">income[</span><span class="c1 c16">which</span><span class="c5 c13">(wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">income</span><span class="c18 c16 c13">&gt;</span><span class="c6 c16">20</span><span class="c5 c13">)] &lt;-</span><span class="c2">&nbsp;</span><span class="c6 c16">4</span><span class="c5"><br><br></span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">state[</span><span class="c1 c16">which</span><span class="c5 c13">(wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">state</span><span class="c18 c16 c13">&lt;=</span><span class="c6 c16">15</span><span class="c5 c13">)] &lt;-</span><span class="c2">&nbsp;</span><span class="c6 c16">1</span><span class="c5"><br></span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">state[</span><span class="c1 c16">which</span><span class="c5 c13">(wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">state</span><span class="c18 c16 c13">&gt;</span><span class="c6 c16">15</span><span class="c5 c13">&nbsp;</span><span class="c18 c16 c13">&amp;</span><span class="c2">&nbsp;</span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">state</span><span class="c18 c16 c13">&lt;=</span><span class="c6 c16">30</span><span class="c5 c13">)] &lt;-</span><span class="c2">&nbsp;</span><span class="c6 c16">2</span><span class="c5"><br></span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">state[</span><span class="c1 c16">which</span><span class="c5 c13">(wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">state</span><span class="c18 c16 c13">&gt;</span><span class="c6 c16">30</span><span class="c5 c13">&nbsp;</span><span class="c18 c16 c13">&amp;</span><span class="c2">&nbsp;</span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">state</span><span class="c18 c16 c13">&lt;=</span><span class="c6 c16">45</span><span class="c5 c13">)] &lt;-</span><span class="c2">&nbsp;</span><span class="c6 c16">3</span><span class="c5"><br></span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">state[</span><span class="c1 c16">which</span><span class="c5 c13">(wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">state</span><span class="c18 c16 c13">&gt;</span><span class="c6 c16">45</span><span class="c5 c13">&nbsp;</span><span class="c18 c16 c13">&amp;</span><span class="c2">&nbsp;</span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">state</span><span class="c18 c16 c13">&lt;=</span><span class="c6 c16">60</span><span class="c5 c13">)] &lt;-</span><span class="c2">&nbsp;</span><span class="c6 c16">4</span><span class="c5"><br><br></span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">year[</span><span class="c1 c16">which</span><span class="c5 c13">(wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">year</span><span class="c18 c16 c13">&lt;=</span><span class="c6 c16">1985</span><span class="c5 c13">)] &lt;-</span><span class="c2">&nbsp;</span><span class="c6 c16">1</span><span class="c5"><br></span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">year[</span><span class="c1 c16">which</span><span class="c5 c13">(wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">year</span><span class="c18 c16 c13">&gt;</span><span class="c6 c16">1985</span><span class="c5 c13">&nbsp;</span><span class="c18 c16 c13">&amp;</span><span class="c2">&nbsp;</span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">year</span><span class="c18 c16 c13">&lt;=</span><span class="c6 c16">1995</span><span class="c5 c13">)] &lt;-</span><span class="c2">&nbsp;</span><span class="c6 c16">2</span><span class="c5"><br></span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">year[</span><span class="c1 c16">which</span><span class="c5 c13">(wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">year</span><span class="c18 c16 c13">&gt;</span><span class="c6 c16">1995</span><span class="c5 c13">&nbsp;</span><span class="c18 c16 c13">&amp;</span><span class="c2">&nbsp;</span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">year</span><span class="c18 c16 c13">&lt;=</span><span class="c6 c16">2005</span><span class="c5 c13">)] &lt;-</span><span class="c2">&nbsp;</span><span class="c6 c16">3</span><span class="c5"><br></span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">year[</span><span class="c1 c16">which</span><span class="c5 c13">(wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">year</span><span class="c18 c16 c13">&gt;</span><span class="c6 c16">2005</span><span class="c5 c13">&nbsp;</span><span class="c18 c16 c13">&amp;</span><span class="c2">&nbsp;</span><span class="c5 c13">wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">year</span><span class="c18 c16 c13">&lt;=</span><span class="c6 c16">2015</span><span class="c5 c13">)] &lt;-</span><span class="c2">&nbsp;</span><span class="c6 c16">4</span><span class="c5"><br><br></span><span class="c5 c13">wage_new &lt;-</span><span class="c2">&nbsp;</span><span class="c5 c13">wage</span><span class="c5"><br></span><span class="c5 c13">ind =</span><span class="c1 c16">sample</span><span class="c5 c13">(</span><span class="c6 c16">1</span><span class="c18 c16 c13">:</span><span class="c1 c16">dim</span><span class="c5 c13">(wage_new)[</span><span class="c6 c16">1</span><span class="c5 c13">], </span><span class="c10 c30 c29 c13">15</span><span class="c6 c16">000</span><span class="c5 c13">)</span><span class="c5"><br></span><span class="c5 c13">wage_test =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_new[ind[</span><span class="c6 c16">1</span><span class="c18 c16 c13">:</span><span class="c6 c29">3</span><span class="c6 c29">0</span><span class="c6 c16">00</span><span class="c5 c13">],]</span><span class="c5"><br></span><span class="c5 c13">wage_train1 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_new[ind[</span><span class="c6 c29">3</span><span class="c6 c16">001</span><span class="c18 c16 c13">:</span><span class="c6 c29">6</span><span class="c6 c16">000</span><span class="c5 c13">],]</span><span class="c5"><br></span><span class="c10 c30 c29 c13">wage_train2 =</span><span class="c7 c29">&nbsp;</span><span class="c10 c30 c29 c13">wage_new[ind[</span><span class="c6 c29">6001</span><span class="c18 c29 c13">:</span><span class="c6 c29">9</span><span class="c6 c29">000</span><span class="c10 c30 c29 c13">],]</span><span class="c10 c30 c29"><br></span><span class="c10 c29 c13 c30">wage_train3 =</span><span class="c7 c29">&nbsp;</span><span class="c10 c30 c29 c13">wage_new[ind[</span><span class="c6 c29">9001</span><span class="c18 c29 c13">:</span><span class="c6 c29">12</span><span class="c6 c29">000</span><span class="c10 c30 c29 c13">],]</span><span class="c10 c30 c29"><br></span><span class="c10 c30 c29 c13">wage_train4 =</span><span class="c7 c29">&nbsp;</span><span class="c10 c30 c29 c13">wage_new[ind[</span><span class="c6 c29">12001</span><span class="c18 c29 c13">:</span><span class="c6 c29">15</span><span class="c6 c29">000</span><span class="c10 c30 c29 c13">],]</span><span class="c5"><br></span></p><p class="c22"><span class="c32 c10 c30 c13 c34"># fit training data1 </span><span class="c5"><br></span><span class="c5 c13">wage_train =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train1</span><span class="c5"><br></span><span class="c5 c13">x1 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train</span><span class="c18 c16 c13">$</span><span class="c5 c13">sex</span><span class="c5"><br></span><span class="c5 c13">x2 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train</span><span class="c18 c16 c13">$</span><span class="c5 c13">white </span><span class="c18 c16 c13">+</span><span class="c6 c16">1</span><span class="c5"><br></span><span class="c5 c13">x3 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train</span><span class="c18 c16 c13">$</span><span class="c5 c13">age </span><span class="c18 c16 c13">+</span><span class="c6 c16">1</span><span class="c5"><br></span><span class="c5 c13">x4 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train</span><span class="c18 c16 c13">$</span><span class="c5 c13">skilled </span><span class="c18 c16 c13">+</span><span class="c6 c16">1</span><span class="c5"><br></span><span class="c5 c13">x5 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train</span><span class="c18 c16 c13">$</span><span class="c5 c13">income</span><span class="c5"><br></span><span class="c5 c13">x6 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train</span><span class="c18 c16 c13">$</span><span class="c5 c13">state</span><span class="c5"><br></span><span class="c5 c13">x7 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train</span><span class="c18 c16 c13">$</span><span class="c5 c13">year</span><span class="c5"><br></span><span class="c5 c13">y =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train</span><span class="c18 c16 c13">$</span><span class="c5 c13">lfp</span><span class="c5"><br><br></span><span class="c32 c10 c30 c13 c34"># prepare the test data</span><span class="c5"><br></span><span class="c5 c13">x1t =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_test</span><span class="c18 c16 c13">$</span><span class="c5 c13">sex</span><span class="c5"><br></span><span class="c5 c13">x2t =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_test</span><span class="c18 c16 c13">$</span><span class="c5 c13">white </span><span class="c18 c16 c13">+</span><span class="c6 c16">1</span><span class="c5"><br></span><span class="c5 c13">x3t =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_test</span><span class="c18 c16 c13">$</span><span class="c5 c13">age </span><span class="c18 c16 c13">+</span><span class="c6 c16">1</span><span class="c5"><br></span><span class="c5 c13">x4t =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_test</span><span class="c18 c16 c13">$</span><span class="c5 c13">skilled </span><span class="c18 c16 c13">+</span><span class="c6 c16">1</span><span class="c5"><br></span><span class="c5 c13">x5t =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_test</span><span class="c18 c16 c13">$</span><span class="c5 c13">income</span><span class="c5"><br></span><span class="c5 c13">x6t =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_test</span><span class="c18 c16 c13">$</span><span class="c5 c13">state</span><span class="c5"><br></span><span class="c5 c13">x7t =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_test</span><span class="c18 c16 c13">$</span><span class="c5 c13">year</span><span class="c5"><br></span><span class="c5 c13">yt =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_test</span><span class="c16 c13 c18">$</span><span class="c5 c13">lfp</span><span class="c5"><br></span><span class="c5 c13">Nt =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(yt)</span><span class="c5"><br><br><br></span><span class="c5 c13">N =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(x1) ## // number of x</span><span class="c5"><br></span><span class="c5 c13">x1_N =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(</span><span class="c1 c16">unique</span><span class="c5 c13">(x1))## // number of categories in x</span><span class="c5"><br></span><span class="c5 c13">x2_N =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(</span><span class="c1 c16">unique</span><span class="c5 c13">(x2)) ##// number of categories in x2</span><span class="c5"><br></span><span class="c5 c13">x3_N =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(</span><span class="c1 c16">unique</span><span class="c5 c13">(x3))</span><span class="c5"><br></span><span class="c5 c13">x4_N =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(</span><span class="c1 c16">unique</span><span class="c5 c13">(x4))</span><span class="c5"><br></span><span class="c5 c13">x5_N =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(</span><span class="c1 c16">unique</span><span class="c5 c13">(x5))</span><span class="c5"><br></span><span class="c5 c13">x6_N =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(</span><span class="c1 c16">unique</span><span class="c5 c13">(x6))</span><span class="c5"><br></span><span class="c5 c13">x7_N =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(</span><span class="c1 c16">unique</span><span class="c5 c13">(x7))</span><span class="c5"><br><br></span><span class="c5 c13">data &lt;-</span><span class="c2">&nbsp;</span><span class="c1 c16">list</span><span class="c5 c13">(</span><span class="c16 c11 c10">x1_N =</span><span class="c5 c13">&nbsp;x1_N, </span><span class="c16 c11 c10">x2_N =</span><span class="c5 c13">&nbsp;x2_N,</span><span class="c16 c11 c10">x3_N =</span><span class="c5 c13">&nbsp;x3_N,</span><span class="c16 c11 c10">x4_N =</span><span class="c5 c13">&nbsp;x4_N,</span><span class="c16 c11 c10">x5_N =</span><span class="c5 c13">&nbsp;x5_N,</span><span class="c16 c11 c10">x6_N =</span><span class="c5 c13">&nbsp;x6_N,</span><span class="c16 c11 c10">x7_N =</span><span class="c5 c13">&nbsp;x7_N,</span><span class="c5"><br></span><span class="c5 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c16 c11 c10">N =</span><span class="c5 c13">&nbsp;N,</span><span class="c16 c11 c10">Nt =</span><span class="c5 c13">&nbsp;Nt, </span><span class="c16 c11 c10">x1 =</span><span class="c5 c13">&nbsp;x1,</span><span class="c16 c11 c10">x2 =</span><span class="c5 c13">&nbsp;x2,</span><span class="c16 c11 c10">x3 =</span><span class="c5 c13">&nbsp;x3,</span><span class="c16 c11 c10">x4 =</span><span class="c5 c13">&nbsp;x4,</span><span class="c16 c11 c10">x5 =</span><span class="c5 c13">&nbsp;x5,</span><span class="c16 c11 c10">x6 =</span><span class="c5 c13">&nbsp;x6,</span><span class="c16 c11 c10">x7 =</span><span class="c5 c13">&nbsp;x7,</span><span class="c16 c11 c10">x1t=</span><span class="c5 c13">x1t,</span><span class="c5"><br></span><span class="c5 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c16 c11 c10">x2t=</span><span class="c5 c13">x2t,</span><span class="c16 c11 c10">x3t=</span><span class="c5 c13">x3t,</span><span class="c16 c11 c10">x4t=</span><span class="c5 c13">x4t,</span><span class="c16 c11 c10">x5t=</span><span class="c5 c13">x5t,</span><span class="c16 c11 c10">x6t=</span><span class="c5 c13">x6t,</span><span class="c16 c11 c10">x7t=</span><span class="c5 c13">x7t,</span><span class="c5"><br></span><span class="c5 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;y)</span><span class="c5"><br><br></span><span class="c5 c13">fit_multi1&lt;-</span><span class="c1 c16">stan</span><span class="c5 c13">(</span><span class="c16 c11 c10">file =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;multi_logit4.stan&quot;</span><span class="c5 c13">,</span><span class="c16 c11 c10">data=</span><span class="c5 c13">data, </span><span class="c16 c11 c10">iter =</span><span class="c5 c13">&nbsp;</span><span class="c6 c16">500</span><span class="c5 c13">, </span><span class="c16 c11 c10">chains=</span><span class="c6 c16">1</span><span class="c5 c13">, </span><span class="c16 c11 c10">control =</span><span class="c5 c13">&nbsp;</span><span class="c1 c16">list</span><span class="c5 c13">(</span><span class="c16 c11 c10">max_treedepth =</span><span class="c5 c13">&nbsp;</span><span class="c6 c16">15</span><span class="c5 c13">))</span></p><p class="c22"><span class="c5 c13">fit_multi1_sum &lt;-</span><span class="c2">&nbsp;</span><span class="c1 c16">extract</span><span class="c5 c13">(fit_multi1)</span><span class="c5"><br></span></p><p class="c22"><span class="c32 c10 c30 c13 c34"># Now let&#39;s see how did we do about prediction on test</span><span class="c5"><br></span><span class="c5 c13">y_pred =</span><span class="c2">&nbsp;</span><span class="c1 c16">apply</span><span class="c5 c13">(fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">y_test, </span><span class="c16 c11 c10">MARGIN =</span><span class="c5 c13">&nbsp;</span><span class="c6 c16">2</span><span class="c5 c13">,</span><span class="c16 c11 c10">FUN =</span><span class="c5 c13">&nbsp;mean)</span><span class="c5"><br></span><span class="c5 c13">y_pred_bin =</span><span class="c2">&nbsp;</span><span class="c1 c16">ifelse</span><span class="c5 c13">(y_pred </span><span class="c18 c16 c13">&gt;=</span><span class="c6 c16">0.5</span><span class="c5 c13">,</span><span class="c6 c16">1</span><span class="c5 c13">,</span><span class="c6 c16">0</span><span class="c5 c13">)</span><span class="c5"><br></span><span class="c5 c13">y_pred_bin1 =</span><span class="c2">&nbsp;</span><span class="c5 c13">y_pred_bin</span><span class="c5"><br><br></span><span class="c32 c10 c30 c13 c34"># The success prediction rate</span><span class="c5"><br></span><span class="c5 c13">pre &lt;-</span><span class="c2">&nbsp;</span><span class="c1 c16">c</span><span class="c5 c13">(pre, </span><span class="c1 c16">mean</span><span class="c5 c13">(y_pred_bin</span><span class="c18 c16 c13">==</span><span class="c5 c13">yt))</span><span class="c5"><br></span><span class="c5 c13">pre</span></p><p class="c22"><span class="c5 c13">## [1] 0.726</span></p><p class="c22"><span class="c5 c13">MSE &lt;-</span><span class="c2">&nbsp;</span><span class="c1 c16">c</span><span class="c5 c13">(MSE, </span><span class="c1 c16">var</span><span class="c5 c13">(y_pred_bin</span><span class="c18 c16 c13">==</span><span class="c5 c13">yt)</span><span class="c18 c16 c13">/</span><span class="c1 c16">length</span><span class="c5 c13">(y_pred_bin) )</span><span class="c5"><br></span><span class="c5 c13">MSE</span></p><p class="c22"><span class="c5 c13">## [1] 0.0001991231</span></p><p class="c22"><span class="c5 c13">fit_summary &lt;-</span><span class="c2">&nbsp;</span><span class="c1 c16">as.data.frame</span><span class="c5 c13">(</span><span class="c1 c16">summary</span><span class="c5 c13">(fit_multi1)</span><span class="c18 c16 c13">$</span><span class="c5 c13">summary)</span><span class="c5"><br><br></span><span class="c32 c10 c30 c13 c34"># Make vector of wanted parameter names</span><span class="c5"><br></span><span class="c5 c13">wanted_pars &lt;-</span><span class="c2">&nbsp;</span><span class="c1 c16">c</span><span class="c5 c13">(</span><span class="c1 c16">paste0</span><span class="c5 c13">(</span><span class="c2">&quot;intercept&quot;</span><span class="c5 c13">),</span><span class="c1 c16">paste0</span><span class="c5 c13">(</span><span class="c2">&quot;x1_coeff[&quot;</span><span class="c5 c13">, </span><span class="c6 c16">1</span><span class="c18 c16 c13">:</span><span class="c5 c13">x1_N,</span><span class="c2">&quot;]&quot;</span><span class="c5 c13">), </span><span class="c1 c16">paste0</span><span class="c5 c13">(</span><span class="c2">&quot;x2_coeff[&quot;</span><span class="c5 c13">,</span><span class="c6 c16">1</span><span class="c18 c16 c13">:</span><span class="c5 c13">x2_N,</span><span class="c2">&quot;]&quot;</span><span class="c5 c13">),</span><span class="c1 c16">paste0</span><span class="c5 c13">(</span><span class="c2">&quot;x3_coeff[&quot;</span><span class="c5 c13">,</span><span class="c6 c16">1</span><span class="c18 c16 c13">:</span><span class="c5 c13">x3_N,</span><span class="c2">&quot;]&quot;</span><span class="c5 c13">),</span><span class="c5"><br></span><span class="c5 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c1 c16">paste0</span><span class="c5 c13">(</span><span class="c2">&quot;x4_coeff[&quot;</span><span class="c5 c13">,</span><span class="c6 c16">1</span><span class="c18 c16 c13">:</span><span class="c5 c13">x4_N,</span><span class="c2">&quot;]&quot;</span><span class="c5 c13">),</span><span class="c1 c16">paste0</span><span class="c5 c13">(</span><span class="c2">&quot;x5_coeff[&quot;</span><span class="c5 c13">,</span><span class="c6 c16">1</span><span class="c18 c16 c13">:</span><span class="c5 c13">x5_N,</span><span class="c2">&quot;]&quot;</span><span class="c5 c13">),</span><span class="c1 c16">paste0</span><span class="c5 c13">(</span><span class="c2">&quot;x6_coeff[&quot;</span><span class="c5 c13">,</span><span class="c6 c16">1</span><span class="c18 c16 c13">:</span><span class="c5 c13">x6_N,</span><span class="c2">&quot;]&quot;</span><span class="c5 c13">),</span><span class="c1 c16">paste0</span><span class="c5 c13">(</span><span class="c2">&quot;x7_coeff[&quot;</span><span class="c5 c13">,</span><span class="c6 c16">1</span><span class="c18 c16 c13">:</span><span class="c5 c13">x7_N,</span><span class="c2">&quot;]&quot;</span><span class="c5 c13">),</span><span class="c1 c16">c</span><span class="c5 c13">(</span><span class="c2">&quot;sigma_x1&quot;</span><span class="c5 c13">,</span><span class="c2">&quot;sigma_x2&quot;</span><span class="c5 c13">,</span><span class="c2">&quot;sigma_x3&quot;</span><span class="c5 c13">,</span><span class="c2">&quot;sigma_x4&quot;</span><span class="c5 c13">,</span><span class="c2">&quot;sigma_x5&quot;</span><span class="c5 c13">,</span><span class="c2">&quot;sigma_x6&quot;</span><span class="c5 c13">,</span><span class="c2">&quot;sigma_x7&quot;</span><span class="c5 c13">))</span><span class="c5"><br><br></span><span class="c32 c10 c30 c13 c34"># Get estimated and generating values for wanted parameters</span><span class="c5"><br></span><span class="c5 c13">estimated_values &lt;-</span><span class="c2">&nbsp;</span><span class="c5 c13">fit_summary[wanted_pars, </span><span class="c1 c16">c</span><span class="c5 c13">(</span><span class="c2">&quot;mean&quot;</span><span class="c5 c13">, </span><span class="c2">&quot;2.5%&quot;</span><span class="c5 c13">, </span><span class="c2">&quot;97.5%&quot;</span><span class="c5 c13">)]</span><span class="c5"><br><br></span><span class="c32 c10 c30 c13 c34"># Assemble a data frame to pass to ggplot()</span><span class="c5"><br></span><span class="c5 c13">sim_df &lt;-</span><span class="c2">&nbsp;</span><span class="c1 c16">data.frame</span><span class="c5 c13">(</span><span class="c16 c11 c10">parameter =</span><span class="c5 c13">&nbsp;</span><span class="c1 c16">factor</span><span class="c5 c13">(wanted_pars, </span><span class="c1 c16">rev</span><span class="c5 c13">(wanted_pars)), </span><span class="c16 c11 c10">row.names =</span><span class="c5 c13">&nbsp;</span><span class="c16 c10 c30 c13 c34">NULL</span><span class="c5 c13">)</span><span class="c5"><br></span><span class="c5 c13">sim_df</span><span class="c18 c16 c13">$</span><span class="c5 c13">middle &lt;-</span><span class="c2">&nbsp;</span><span class="c5 c13">estimated_values[, </span><span class="c2">&quot;mean&quot;</span><span class="c5 c13">] </span><span class="c5"><br></span><span class="c5 c13">sim_df</span><span class="c18 c16 c13">$</span><span class="c5 c13">lower &lt;-</span><span class="c2">&nbsp;</span><span class="c5 c13">estimated_values[, </span><span class="c2">&quot;2.5%&quot;</span><span class="c5 c13">] </span><span class="c5"><br></span><span class="c5 c13">sim_df</span><span class="c18 c16 c13">$</span><span class="c5 c13">upper &lt;-</span><span class="c2">&nbsp;</span><span class="c5 c13">estimated_values[, </span><span class="c2">&quot;97.5%&quot;</span><span class="c5 c13">] </span><span class="c5"><br><br></span><span class="c32 c10 c30 c13 c34"># Plot the posterior estimation o</span><span class="c10 c30 c13 c34">f</span><span class="c32 c10 c30 c13 c34">&nbsp;the parameters</span><span class="c5"><br></span><span class="c1 c16">ggplot</span><span class="c5 c13">(sim_df) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">x =</span><span class="c5 c13">&nbsp;parameter, </span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;middle, </span><span class="c16 c11 c10">ymin =</span><span class="c5 c13">&nbsp;lower, </span><span class="c16 c11 c10">ymax =</span><span class="c5 c13">&nbsp;upper) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">scale_x_discrete</span><span class="c5 c13">() </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c1 c16">geom_abline</span><span class="c5 c13">(</span><span class="c16 c11 c10">intercept =</span><span class="c5 c13">&nbsp;</span><span class="c6 c16">0</span><span class="c5 c13">, </span><span class="c16 c11 c10">slope =</span><span class="c5 c13">&nbsp;</span><span class="c6 c16">0</span><span class="c5 c13">, </span><span class="c16 c11 c10">color =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;white&quot;</span><span class="c5 c13">) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_linerange</span><span class="c5 c13">() </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c1 c16">geom_point</span><span class="c5 c13">(</span><span class="c16 c11 c10">size =</span><span class="c5 c13">&nbsp;</span><span class="c6 c16">2</span><span class="c5 c13">) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c1 c16">labs</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;Estimation&quot;</span><span class="c5 c13">, </span><span class="c16 c11 c10">x =</span><span class="c5 c13">&nbsp;</span><span class="c16 c10 c30 c13 c34">NULL</span><span class="c5 c13">) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">theme</span><span class="c5 c13">(</span><span class="c16 c11 c10">panel.grid =</span><span class="c5 c13">&nbsp;</span><span class="c1 c16">element_blank</span><span class="c5 c13">()) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c1 c16">coord_flip</span><span class="c5 c13">()</span></p><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 522.00px; height: 417.60px;"><img alt="" src="images/image24.png" style="width: 522.00px; height: 417.60px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c45"><span class="c32 c9 c23">Fig 2.1.1: Posterior Estimation of the Parameters</span></p><p class="c45 c39"><span class="c26 c23"></span></p><h3 class="c40 c31" id="h.5fkfpkh94ki"><span class="c3">2.1.2 Model Checking </span></h3><p class="c22"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c26 c23">We summarize our model by graphing out the posterior estimation of the parameters, with its mean and the 95% credible region. By a quick look at the Fig 2.1.1, we can see that this model performs poorly on two predictors: year and state. There are several potential reasons we need figure out. &nbsp;For the year predictor, performing regression on year is not potentially a good idea as we realized later, because a time series model is better suited to estimate the potential periodic behavior in this data. As for the state predictor, the criterion we have chosen to group these 51 states may be too vague to capture any useful insights from our model. &nbsp;In this project, the temporal analysis on the labor force participation rate is not the main objective. However, we can solve that later by looking at the state individually. </span></p><p class="c22"><span class="c26 c23">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Further, we want to make sure the parameters are converged by looking at the Fig 2.1.2. We plot out the R-hat statistics for all of the posterior draws of the parameters and we could clearly observe that the R-hat statistics are all lower than 1.1. So this model yields convergent estimation of the parameters. However, when examining the trace plot of the parameters, we see that some of the coefficients for the age and income predictors perform not that good, which also can be observed in Fig 2.1.1. &nbsp;But good news is that, there is no clear indication that these coefficients are strongly bias. So one theory for the variation for these coefficients is caused by relatively small iteration of the draws, which will be solved if we have increased the iteration to significantly larger. But due to the limitation of the computational power, we leave this matter as trivial. </span></p><p class="c22 c39"><span class="c26 c23"></span></p><p class="c22"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 334.67px;"><img alt="" src="images/image25.png" style="width: 624.00px; height: 334.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c45"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c32 c9 c23">Fig 2.1.2: R-hat Statistics for All Parameters in the Model</span></p><p class="c22"><span class="c32 c9 c23">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c22"><span class="c32 c10 c30 c13 c34">library(ggplot2)</span><span class="c5"><br></span><span class="c5 c13">coef &lt;-</span><span class="c2">&nbsp;</span><span class="c1 c16">cbind</span><span class="c5 c13">(fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x1_coeff[,</span><span class="c6 c16">1</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x1_coeff[,</span><span class="c6 c16">2</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x2_coeff[,</span><span class="c6 c16">1</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x2_coeff[,</span><span class="c6 c16">2</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x3_coeff[,</span><span class="c6 c16">1</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x3_coeff[,</span><span class="c6 c16">2</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x3_coeff[,</span><span class="c6 c16">3</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x3_coeff[,</span><span class="c6 c16">4</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x4_coeff[,</span><span class="c6 c16">1</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x4_coeff[,</span><span class="c6 c16">2</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x5_coeff[,</span><span class="c6 c16">1</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x5_coeff[,</span><span class="c6 c16">2</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x5_coeff[,</span><span class="c6 c16">3</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x5_coeff[,</span><span class="c6 c16">4</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x6_coeff[,</span><span class="c6 c16">1</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x6_coeff[,</span><span class="c6 c16">2</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x6_coeff[,</span><span class="c6 c16">3</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x6_coeff[,</span><span class="c6 c16">4</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x7_coeff[,</span><span class="c6 c16">1</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x7_coeff[,</span><span class="c6 c16">2</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x7_coeff[,</span><span class="c6 c16">3</span><span class="c5 c13">],fit_multi1_sum</span><span class="c18 c16 c13">$</span><span class="c5 c13">x7_coeff[,</span><span class="c6 c16">4</span><span class="c5 c13">])</span><span class="c5"><br></span><span class="c5 c13">index =</span><span class="c2">&nbsp;</span><span class="c1 c16">seq</span><span class="c5 c13">(</span><span class="c6 c16">1</span><span class="c18 c16 c13">:</span><span class="c1 c16">nrow</span><span class="c5 c13">(coef))</span><span class="c5"><br></span><span class="c5 c13">coef =</span><span class="c2">&nbsp;</span><span class="c1 c16">as.data.frame</span><span class="c5 c13">(</span><span class="c1 c16">cbind</span><span class="c5 c13">(index,coef))</span><span class="c5"><br><br></span><span class="c1 c16">ggplot</span><span class="c5 c13">(coef, </span><span class="c1 c16">aes</span><span class="c5 c13">(index)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">2</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;sex1&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">3</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;sex2&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">4</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;white1&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">5</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;white2&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">6</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;age1&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">7</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;age2&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">8</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;age3&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">9</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;age4&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">10</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;skill1&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">11</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;skill2&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">12</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;income1&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">13</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;income2&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">14</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;income3&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">15</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;income4&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">16</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;state1&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">17</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;state2&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">18</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;state3&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">19</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;state4&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">20</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;year1&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">21</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;year2&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">22</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;year3&quot;</span><span class="c5 c13">)) </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5"><br></span><span class="c2">&nbsp; </span><span class="c1 c16">geom_line</span><span class="c5 c13">(</span><span class="c1 c16">aes</span><span class="c5 c13">(</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;coef[,</span><span class="c6 c16">23</span><span class="c5 c13">], </span><span class="c16 c11 c10">colour =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;year4&quot;</span><span class="c5 c13">)) &nbsp;</span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c1 c16">labs</span><span class="c5 c13">(</span><span class="c16 c11 c10">y=</span><span class="c2">&#39;Coefficient&#39;</span><span class="c5 c13">)</span></p><p class="c42"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 622.00px; height: 400.00px;"><img alt="../../../../../com.tencent.xinWeChat/Data/Library/Application%20Support/com.tencent.xinWeChat/2.0b4.0.9/c88afeb4fcc46e563f99ef44c328e954/Message/MessageTemp/e0974ac57abc41c678d8aff8ead4e403/Image/4821544284529_.pic_hd.jpg" src="images/image26.jpg" style="width: 622.00px; height: 400.00px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c17"><span class="c19 c9">Fig 2.1.3: Trace-plots of Coefficients of Predictors</span></p><p class="c22 c39"><span class="c4"></span></p><h2 class="c40" id="h.x7jpb8fc740p"><span class="c23 c46 c28">2.2 Model Fitting for Each State</span></h2><h3 class="c51" id="h.w1911mk8e672"><span class="c23 c28">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3">2.2.1 Model Checking and Summary</span></h3><p class="c20"><span class="c23">Based on the inference from previous model, we observe that the model does not capture the impact from the state to the labor force participation very well. Therefore, we decide to examine the remaining predictors while fixing the states. To do this, we simply subset the data set into 51 datasets by states. Since the dataset is enormous, these subsets are large and will cause runtime error as we have discussed previously. &nbsp;So, we apply the same trick to draw random samples from each state subset. The following analysis are based on New York state subset. </span><span class="c4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c22"><span class="c32 c10 c30 c13 c34">#Taking New York as an example:</span></p><p class="c22"><span class="c5 c13">state =</span><span class="c2">&nbsp;</span><span class="c6 c16">36 </span><span class="c10 c30 c13 c34"># New York</span><span class="c5"><br></span><span class="c5 c13">wage_new =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage[</span><span class="c1 c16">which</span><span class="c5 c13">(wage</span><span class="c18 c16 c13">$</span><span class="c5 c13">state </span><span class="c18 c16 c13">==</span><span class="c2">&nbsp;</span><span class="c5 c13">state),]</span><span class="c5"><br></span><span class="c5 c13">ind =</span><span class="c1 c16">sample</span><span class="c5 c13">(</span><span class="c6 c16">1</span><span class="c18 c16 c13">:</span><span class="c1 c16">dim</span><span class="c5 c13">(wage_new)[</span><span class="c6 c16">1</span><span class="c5 c13">], </span><span class="c6 c16">15000</span><span class="c5 c13">)</span><span class="c5"><br></span><span class="c5 c13">wage_test =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_new[ind[</span><span class="c6 c16">1</span><span class="c18 c16 c13">:</span><span class="c6 c16">3000</span><span class="c5 c13">],]</span><span class="c5"><br></span><span class="c5 c13">wage_train1 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_new[ind[</span><span class="c6 c16">3001</span><span class="c18 c16 c13">:</span><span class="c6 c16">6000</span><span class="c5 c13">],]</span><span class="c5"><br></span><span class="c5 c13">wage_train2 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_new[ind[</span><span class="c6 c16">6001</span><span class="c18 c16 c13">:</span><span class="c6 c16">9000</span><span class="c5 c13">],]</span><span class="c5"><br></span><span class="c5 c13">wage_train3 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_new[ind[</span><span class="c6 c16">9001</span><span class="c18 c16 c13">:</span><span class="c6 c16">12000</span><span class="c5 c13">],]</span><span class="c5"><br></span><span class="c5 c13">wage_train4 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_new[ind[</span><span class="c6 c16">12001</span><span class="c18 c16 c13">:</span><span class="c6 c16">15000</span><span class="c5 c13">],]</span><span class="c5"><br><br></span><span class="c32 c10 c30 c13 c34"># fit training data1 </span><span class="c5"><br></span><span class="c5 c13">wage_train =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train1</span><span class="c5"><br></span><span class="c5 c13">x1 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train</span><span class="c18 c16 c13">$</span><span class="c5 c13">sex</span><span class="c5"><br></span><span class="c5 c13">x2 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train</span><span class="c18 c16 c13">$</span><span class="c5 c13">white </span><span class="c18 c16 c13">+</span><span class="c6 c16">1</span><span class="c5"><br></span><span class="c5 c13">x3 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train</span><span class="c18 c16 c13">$</span><span class="c5 c13">age </span><span class="c18 c16 c13">+</span><span class="c6 c16">1</span><span class="c5"><br></span><span class="c5 c13">x4 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train</span><span class="c18 c16 c13">$</span><span class="c5 c13">skilled </span><span class="c18 c16 c13">+</span><span class="c6 c16">1</span><span class="c5"><br></span><span class="c5 c13">x5 =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train</span><span class="c18 c16 c13">$</span><span class="c5 c13">income</span><span class="c5"><br></span><span class="c5 c13">y =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_train</span><span class="c18 c16 c13">$</span><span class="c5 c13">lfp</span><span class="c5"><br><br></span><span class="c32 c10 c30 c13 c34"># prepare the test data</span><span class="c5"><br></span><span class="c5 c13">x1t =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_test</span><span class="c18 c16 c13">$</span><span class="c5 c13">sex</span><span class="c5"><br></span><span class="c5 c13">x2t =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_test</span><span class="c18 c16 c13">$</span><span class="c5 c13">white </span><span class="c18 c16 c13">+</span><span class="c6 c16">1</span><span class="c5"><br></span><span class="c5 c13">x3t =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_test</span><span class="c18 c16 c13">$</span><span class="c5 c13">age </span><span class="c18 c16 c13">+</span><span class="c6 c16">1</span><span class="c5"><br></span><span class="c5 c13">x4t =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_test</span><span class="c18 c16 c13">$</span><span class="c5 c13">skilled </span><span class="c18 c16 c13">+</span><span class="c6 c16">1</span><span class="c5"><br></span><span class="c5 c13">x5t =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_test</span><span class="c18 c16 c13">$</span><span class="c5 c13">income</span><span class="c5"><br></span><span class="c5 c13">yt =</span><span class="c2">&nbsp;</span><span class="c5 c13">wage_test</span><span class="c18 c16 c13">$</span><span class="c5 c13">lfp</span><span class="c5"><br></span><span class="c5 c13">Nt =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(yt)</span><span class="c5"><br><br></span><span class="c5 c13">N =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(x1) ## // number of x</span><span class="c5"><br></span><span class="c5 c13">x1_N =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(</span><span class="c1 c16">unique</span><span class="c5 c13">(x1)) #</span><span class="c10 c30 c29 c13">&nbsp;</span><span class="c5 c13">number of categories in x</span><span class="c5"><br></span><span class="c5 c13">x2_N =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(</span><span class="c1 c16">unique</span><span class="c5 c13">(x2))</span><span class="c5"><br></span><span class="c5 c13">x3_N =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(</span><span class="c1 c16">unique</span><span class="c5 c13">(x3))</span><span class="c5"><br></span><span class="c5 c13">x4_N =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(</span><span class="c1 c16">unique</span><span class="c5 c13">(x4))</span><span class="c5"><br></span><span class="c5 c13">x5_N =</span><span class="c2">&nbsp;</span><span class="c1 c16">length</span><span class="c5 c13">(</span><span class="c1 c16">unique</span><span class="c5 c13">(x5))</span><span class="c5"><br><br></span><span class="c5 c13">data &lt;-</span><span class="c2">&nbsp;</span><span class="c1 c16">list</span><span class="c5 c13">(</span><span class="c16 c11 c10">x1_N =</span><span class="c5 c13">&nbsp;x1_N, </span><span class="c16 c11 c10">x2_N =</span><span class="c5 c13">&nbsp;x2_N,</span><span class="c16 c11 c10">x3_N =</span><span class="c5 c13">&nbsp;x3_N,</span><span class="c16 c11 c10">x4_N =</span><span class="c5 c13">&nbsp;x4_N,</span><span class="c16 c11 c10">x5_N =</span><span class="c5 c13">&nbsp;x5_N,</span><span class="c16 c11 c10">x6_N =</span><span class="c5 c13">&nbsp;x6_N,</span><span class="c5"><br></span><span class="c5 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c16 c11 c10">N =</span><span class="c5 c13">&nbsp;N,</span><span class="c16 c11 c10">Nt =</span><span class="c5 c13">&nbsp;Nt, </span><span class="c16 c11 c10">x1 =</span><span class="c5 c13">&nbsp;x1,</span><span class="c16 c11 c10">x2 =</span><span class="c5 c13">&nbsp;x2,</span><span class="c16 c11 c10">x3 =</span><span class="c5 c13">&nbsp;x3,</span><span class="c16 c11 c10">x4 =</span><span class="c5 c13">&nbsp;x4,</span><span class="c16 c11 c10">x5 =</span><span class="c5 c13">&nbsp;x5,</span><span class="c16 c11 c10">x6 =</span><span class="c5 c13">&nbsp;x6,</span><span class="c16 c11 c10">x1t=</span><span class="c5 c13">x1t,</span><span class="c5"><br></span><span class="c5 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c16 c11 c10">x2t=</span><span class="c5 c13">x2t,</span><span class="c16 c11 c10">x3t=</span><span class="c5 c13">x3t,</span><span class="c16 c11 c10">x4t=</span><span class="c5 c13">x4t,</span><span class="c16 c11 c10">x5t=</span><span class="c5 c13">x5t,</span><span class="c16 c11 c10">x6t=</span><span class="c5 c13">x6t,</span><span class="c5"><br></span><span class="c5 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c16 c11 c10">y =</span><span class="c5 c13">&nbsp;y)</span><span class="c5"><br><br></span><span class="c5 c13">fit_multi1&lt;-</span><span class="c1 c16">stan</span><span class="c5 c13">(</span><span class="c16 c11 c10">file =</span><span class="c5 c13">&nbsp;</span><span class="c2">&quot;multi_logit3.stan&quot;</span><span class="c5 c13">,</span><span class="c16 c11 c10">data=</span><span class="c5 c13">data, </span><span class="c16 c11 c10">iter =</span><span class="c5 c13">&nbsp;</span><span class="c6 c16">500</span><span class="c5 c13">, </span><span class="c16 c11 c10">chains=</span><span class="c6 c16">1</span><span class="c5 c13">, </span><span class="c16 c11 c10">control =</span><span class="c5 c13">&nbsp;</span><span class="c1 c16">list</span><span class="c5 c13">(</span><span class="c16 c11 c10">max_treedepth =</span><span class="c5 c13">&nbsp;</span><span class="c6 c16">15</span><span class="c5 c13">))</span></p><p class="c22"><span class="c5 c13">fit_multi1_sum &lt;-</span><span class="c2">&nbsp;</span><span class="c1 c16">extract</span><span class="c5 c13">(fit_multi1)</span><span class="c5"><br></span></p><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 574.83px; height: 308.05px;"><img alt="" src="images/image21.png" style="width: 574.83px; height: 308.05px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c17"><span class="c19 c9">Fig 2.2.1: &nbsp;Posterior Estimation of the Parameters</span></p><p class="c20"><span class="c26 c23">To check the parameters easier, we examine the posterior estimation of the parameters by visualising the simulation from the Stan model output. Fig 2.2.1 provides an comprehensive outlook that captures the coefficients of the predictors and the error scale. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;We also examine the convergence of the parameters by using R-hat statistics and conclude that all of the parameters do converge. We also have the trace-plot available for coefficients as a reference. </span></p><p class="c42"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 361.33px;"><img alt="" src="images/image20.png" style="width: 624.00px; height: 361.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c17"><span class="c19 c9">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fig 2.2.2: Trace-plot of Posterior Estimation for Coefficients</span></p><h3 class="c40 c31" id="h.y3lqf4wp2glh"><span class="c23 c28 c79">2.2.2 Model Evaluation</span></h3><p class="c22 c31"><span class="c23">Fortunate for us, we have a luxurious large dataset which enables us to perform out-of-sample predictive accuracy using the available data. In section 2.2.1, we have mentioned the possible prediction using the posterior estimated parameters in Stan. In the data preparation, we have seperated the 15,000 entries of data into 5 folds, where one fold with 3,000 entries is left as a test set. Therefore, including this toy model which only considered NY state, we will perform the model on each of the 4 training set and compare their results to the test set. The prediction rates are obtained using a simplified version of confusion matrix where we calculate the rate of the number of successful predictions. The following code snippet shows the results from the first training set which is 0.739. </span></p><p class="c22"><span class="c5 c13">y_pred = apply(fit_multi1_sum$y_test, MARGIN = 2,FUN = mean)<br>y_pred_bin = ifelse(y_pred &gt;=0.5,1,0)<br>y_pred_bin1 = y_pred_bin<br><br># The success prediction rate<br>mean(y_pred_bin==yt)</span></p><p class="c22"><span class="c5 c13">## [1] 0.739</span></p><p class="c42"><span class="c4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c42"><span class="c26 c23">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In order to avoid overfitting, we also replicates the process by fitting the model to the remaining training sets and then evaluating the predictive accuracy to the holdout test set. The results for the process are shown in the Fig 2.2.3. We visualize the replicated results in the Fig 2.2.3. The performance of the model remains relatively stable across the training set. The overall prediction is adequately appropriate and the results run on the training set4 provides nearly perfect prediction on the test set, showing that the model generalizes the data decently well and we are on the right track in selecting the model. </span></p><p class="c17"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 553.50px; height: 320.21px;"><img alt="" src="images/image23.png" style="width: 553.50px; height: 320.21px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c17"><span class="c23 c30">Fig 2.2.3: Labor Force Participation Prediction (NY state)</span></p><p class="c20"><span class="c23">Therefore, we have confidence in expanding the model to the remaining 50 states and retrieve the prediction rate for each state. The summary of the results are shown in the Figure 2.2.4. The prediction rate on the states are fairly stable, ranging from 0.7 to 0.8. &nbsp;However, &nbsp;the variation of the prediction rates may be better explained in a detailed study, which we will leave out this part to the potential model expansion.</span></p><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 489.00px; height: 292.86px;"><img alt="" src="images/image27.png" style="width: 489.00px; height: 292.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c17"><span class="c23 c30">Fig 2.2.4: Prediction Rate for Each State (50 States)</span></p><p class="c42 c39"><span class="c4"></span></p><h2 class="c51" id="h.t23jzxi1ywj"><span class="c32 c12 c46 c28">2.3 A Vectorization Version of the Multi-Logit Regression Model</span></h2><p class="c42"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c26 c23">Since we have examine the application of multi-logit regression model to our data, we are very confident about the model and the next thing we consider is to speed up the computation by apply the vectorization form of the predictors. In the stan book, it provides a snippet of stan code to allows us to build the model with a valid start. In our case, we modify the Stan model as the following:</span></p><p class="c22"><span class="c10 c30">#############################Stan Code##################################<br># Multilogit Stan<br>data {<br> &nbsp;int&lt;lower=2&gt; K; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // number of categories<br> &nbsp;int&lt;lower=2&gt; D; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // number of predictors<br> &nbsp;int&lt;lower=0&gt; N; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // number of observations<br> &nbsp;matrix[N, D] x; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // predictors<br> &nbsp;int&lt;lower=1,upper=K&gt; y[N]; &nbsp;// observations<br>}<br>parameters {<br>matrix[K, D] beta; &nbsp; &nbsp; &nbsp;// slopes<br>}<br>model {<br> &nbsp;matrix[N, K] gamma;<br> &nbsp;gamma = x * beta&#39;;<br> <br> &nbsp;// prior<br> &nbsp;to_vector(beta) ~ normal(0, 5);<br> <br> &nbsp;// likelihood<br> &nbsp;for (n in 1:N)<br> &nbsp; &nbsp;y[n] ~ categorical_logit(gamma[n]&#39;);<br>}</span></p><p class="c42"><span class="c4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c20"><span class="c26 c23">The above stan model will provides a similar results to the previous data while speeding &nbsp;up the computation. One caveat of using this stan codes is that we generally should incorporate a column of ones when using the vectorization form of the predictors, otherwise, we would not be able to examine the intercepts of the regression. The following output from stan provides a sample outcomes from this snippet:</span></p><p class="c42 c39"><span class="c26 c23"></span></p><p class="c14"><span class="c32 c9 c10">Inference for Stan model: multi_logit.</span></p><p class="c14"><span class="c9 c10 c32">1 chains, each with iter=200; warmup=100; thin=1; </span></p><p class="c14"><span class="c32 c9 c10">post-warmup draws per chain=100, total post-warmup draws=100.</span></p><p class="c14 c39"><span class="c32 c9 c10"></span></p><p class="c14"><span class="c32 c9 c10">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mean se_mean &nbsp; sd &nbsp; &nbsp; 2.5% &nbsp; &nbsp; &nbsp;25% &nbsp; &nbsp; &nbsp;50% &nbsp; &nbsp; &nbsp;75% &nbsp; &nbsp;97.5% n_eff Rhat</span></p><p class="c14"><span class="c32 c9 c10">beta[1,1] &nbsp; &nbsp;-0.51 &nbsp; &nbsp;0.43 3.50 &nbsp; &nbsp;-7.18 &nbsp; &nbsp;-2.94 &nbsp; &nbsp;-0.63 &nbsp; &nbsp; 2.10 &nbsp; &nbsp; 5.44 &nbsp; &nbsp;68 0.99</span></p><p class="c14"><span class="c32 c9 c10">beta[1,2] &nbsp; &nbsp;-0.40 &nbsp; &nbsp;0.39 3.57 &nbsp; &nbsp;-6.93 &nbsp; &nbsp;-2.91 &nbsp; &nbsp;-0.35 &nbsp; &nbsp; 2.25 &nbsp; &nbsp; 6.50 &nbsp; &nbsp;84 1.00</span></p><p class="c14"><span class="c32 c9 c10">beta[1,3] &nbsp; &nbsp;-0.04 &nbsp; &nbsp;0.45 3.79 &nbsp; &nbsp;-7.85 &nbsp; &nbsp;-2.61 &nbsp; &nbsp; 0.24 &nbsp; &nbsp; 2.37 &nbsp; &nbsp; 7.22 &nbsp; &nbsp;72 0.99</span></p><p class="c14"><span class="c32 c9 c10">beta[1,4] &nbsp; &nbsp;-0.25 &nbsp; &nbsp;0.47 4.14 &nbsp; &nbsp;-7.43 &nbsp; &nbsp;-3.50 &nbsp; &nbsp;-0.45 &nbsp; &nbsp; 3.00 &nbsp; &nbsp; 7.07 &nbsp; &nbsp;77 0.99</span></p><p class="c14"><span class="c32 c9 c10">beta[1,5] &nbsp; &nbsp;-1.08 &nbsp; &nbsp;0.40 3.48 &nbsp; &nbsp;-7.71 &nbsp; &nbsp;-3.51 &nbsp; &nbsp;-0.90 &nbsp; &nbsp; 0.83 &nbsp; &nbsp; 6.12 &nbsp; &nbsp;76 1.02</span></p><p class="c14"><span class="c32 c9 c10">beta[1,6] &nbsp; &nbsp;-0.91 &nbsp; &nbsp;0.42 3.23 &nbsp; &nbsp;-7.20 &nbsp; &nbsp;-3.46 &nbsp; &nbsp;-0.60 &nbsp; &nbsp; 1.65 &nbsp; &nbsp; 4.16 &nbsp; &nbsp;58 1.01</span></p><p class="c14"><span class="c32 c9 c10">beta[2,1] &nbsp; &nbsp; 0.23 &nbsp; &nbsp;0.43 3.51 &nbsp; &nbsp;-6.36 &nbsp; &nbsp;-2.27 &nbsp; &nbsp; 0.10 &nbsp; &nbsp; 2.79 &nbsp; &nbsp; 6.18 &nbsp; &nbsp;67 0.99</span></p><p class="c14"><span class="c32 c9 c10">beta[2,2] &nbsp; &nbsp;-0.71 &nbsp; &nbsp;0.39 3.57 &nbsp; &nbsp;-7.26 &nbsp; &nbsp;-3.19 &nbsp; &nbsp;-0.68 &nbsp; &nbsp; 1.95 &nbsp; &nbsp; 6.17 &nbsp; &nbsp;83 1.00</span></p><p class="c14"><span class="c32 c9 c10">beta[2,3] &nbsp; &nbsp; 0.03 &nbsp; &nbsp;0.45 3.79 &nbsp; &nbsp;-7.80 &nbsp; &nbsp;-2.56 &nbsp; &nbsp; 0.32 &nbsp; &nbsp; 2.48 &nbsp; &nbsp; 7.25 &nbsp; &nbsp;72 0.99</span></p><p class="c14"><span class="c32 c9 c10">beta[2,4] &nbsp; &nbsp;-0.67 &nbsp; &nbsp;0.47 4.14 &nbsp; &nbsp;-7.86 &nbsp; &nbsp;-3.94 &nbsp; &nbsp;-0.87 &nbsp; &nbsp; 2.60 &nbsp; &nbsp; 6.66 &nbsp; &nbsp;77 0.99</span></p><p class="c14"><span class="c32 c9 c10">beta[2,5] &nbsp; &nbsp;-0.78 &nbsp; &nbsp;0.40 3.48 &nbsp; &nbsp;-7.41 &nbsp; &nbsp;-3.20 &nbsp; &nbsp;-0.59 &nbsp; &nbsp; 1.16 &nbsp; &nbsp; 6.46 &nbsp; &nbsp;76 1.02</span></p><p class="c14"><span class="c32 c9 c10">beta[2,6] &nbsp; &nbsp; 0.60 &nbsp; &nbsp;0.43 3.25 &nbsp; &nbsp;-5.64 &nbsp; &nbsp;-1.76 &nbsp; &nbsp; 0.87 &nbsp; &nbsp; 3.07 &nbsp; &nbsp; 5.86 &nbsp; &nbsp;59 1.00</span></p><p class="c14"><span class="c32 c9 c10">lp__ &nbsp; &nbsp; &nbsp;-1756.15 &nbsp; &nbsp;0.26 2.21 -1760.14 -1757.84 -1756.12 -1754.57 -1752.15 &nbsp; &nbsp;71 1.03</span></p><p class="c14 c39"><span class="c32 c9 c10"></span></p><p class="c14"><span class="c32 c9 c10"># Samples were drawn using NUTS(diag_e) at Sun Dec 09 16:18:05 2018.</span></p><p class="c14"><span class="c32 c9 c10"># For each parameter, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence, Rhat=1).</span></p><p class="c42 c39"><span class="c26 c23"></span></p><h1 class="c43" id="h.5lrt58kw8bmm"><span class="c23 c28">3. Potential Model Expansion</span></h1><h2 class="c40"><span class="c23 c46 c28">3.1 Varying Intercept Model with No Predictors</span></h2><p class="c20"><span class="c23">To analyze the relationship between each variable and labor force participation more specifically, we group people with specific variable and then compute their labor force participation rate by the total number of people in the group dividing the number of people who work. <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c23 c28">Considering the simplest multilevel model for the </span><span class="c23">labor force participation rate of the group to which every respondent belongs</span><span class="c23 c28">&nbsp;nested within </span><span class="c23">other 7 variables, w</span><span class="c26 c23">e can write a two-level varying intercept model with no predictors using the usual two-stage formulation as </span></p><p class="c17"><img src="images/image3.png"><span class="c26 c23">&nbsp; &nbsp; </span></p><p class="c17"><span class="c23 c28">&nbsp; </span><img src="images/image4.png"><span class="c23 c28">&nbsp;</span></p><p class="c42"><span class="c23 c28">where </span><span class="c23">we will insert </span><img src="images/image5.png"><span class="c23 c28">&nbsp;</span><span class="c23">a</span><span class="c23 c28">s the </span><span class="c23">labor force participation</span><span class="c23 c28">&nbsp;rate</span><span class="c23">&nbsp;and</span><span class="c23 c28">&nbsp;</span><img src="images/image6.png"><span class="c23 c28">&nbsp;</span><span class="c26 c23">as different variables. After attempting all 7 variables, we find that income is the one with smallest Akaike information criterion(AIC). Below, we can see the comparison of this model based on state and income:</span></p><h3 class="c44" id="h.c5d4gz5j9as8"><span class="c3"></span></h3><h3 class="c51" id="h.lv5nrfjm0rbx"><span class="c3">3.1.1 Labor Force Participation Rate based on State</span></h3><p class="c22"><span class="c8 c32">M1_stanlmer &lt;- stan_lmer(formula = lfpr ~ 1 + (1 | state),<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; data = state,<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; seed = 349)</span></p><p class="c22"><span class="c9 c10">## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 1).</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Gradient evaluation took 0.000313 seconds</span><span class="c9"><br></span><span class="c9 c10">## 1000 transitions using 10 leapfrog steps per transition would take 3.13 seconds.</span><span class="c9"><br></span><span class="c9 c10">## Adjust your expectations accordingly!</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp; &nbsp;1 / 2000 [ &nbsp;0%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;200 / 2000 [ 10%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;400 / 2000 [ 20%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;600 / 2000 [ 30%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;800 / 2000 [ 40%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1000 / 2000 [ 50%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1001 / 2000 [ 50%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1200 / 2000 [ 60%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1400 / 2000 [ 70%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1600 / 2000 [ 80%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1800 / 2000 [ 90%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 2000 / 2000 [100%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## &nbsp;Elapsed Time: 23.1431 seconds (Warm-up)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;5.40667 seconds (Sampling)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;28.5497 seconds (Total)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 2).</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Gradient evaluation took 0.000159 seconds</span><span class="c9"><br></span><span class="c9 c10">## 1000 transitions using 10 leapfrog steps per transition would take 1.59 seconds.</span><span class="c9"><br></span><span class="c9 c10">## Adjust your expectations accordingly!</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp; &nbsp;1 / 2000 [ &nbsp;0%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;200 / 2000 [ 10%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;400 / 2000 [ 20%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;600 / 2000 [ 30%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;800 / 2000 [ 40%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1000 / 2000 [ 50%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1001 / 2000 [ 50%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1200 / 2000 [ 60%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1400 / 2000 [ 70%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1600 / 2000 [ 80%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1800 / 2000 [ 90%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 2000 / 2000 [100%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## &nbsp;Elapsed Time: 24.1687 seconds (Warm-up)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;7.48834 seconds (Sampling)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;31.657 seconds (Total)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 3).</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Gradient evaluation took 0.000159 seconds</span><span class="c9"><br></span><span class="c9 c10">## 1000 transitions using 10 leapfrog steps per transition would take 1.59 seconds.</span><span class="c9"><br></span><span class="c9 c10">## Adjust your expectations accordingly!</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp; &nbsp;1 / 2000 [ &nbsp;0%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;200 / 2000 [ 10%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;400 / 2000 [ 20%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;600 / 2000 [ 30%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;800 / 2000 [ 40%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1000 / 2000 [ 50%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1001 / 2000 [ 50%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1200 / 2000 [ 60%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1400 / 2000 [ 70%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1600 / 2000 [ 80%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1800 / 2000 [ 90%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 2000 / 2000 [100%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## &nbsp;Elapsed Time: 19.2271 seconds (Warm-up)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;5.50527 seconds (Sampling)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;24.7324 seconds (Total)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 4).</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Gradient evaluation took 0.000167 seconds</span><span class="c9"><br></span><span class="c9 c10">## 1000 transitions using 10 leapfrog steps per transition would take 1.67 seconds.</span><span class="c9"><br></span><span class="c9 c10">## Adjust your expectations accordingly!</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp; &nbsp;1 / 2000 [ &nbsp;0%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;200 / 2000 [ 10%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;400 / 2000 [ 20%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;600 / 2000 [ 30%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;800 / 2000 [ 40%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1000 / 2000 [ 50%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1001 / 2000 [ 50%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1200 / 2000 [ 60%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1400 / 2000 [ 70%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1600 / 2000 [ 80%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1800 / 2000 [ 90%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 2000 / 2000 [100%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## &nbsp;Elapsed Time: 26.9976 seconds (Warm-up)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;5.83871 seconds (Sampling)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;32.8363 seconds (Total)</span></p><p class="c42 c39"><span class="c26 c23"></span></p><p class="c42"><span class="c26 c23">After fitting a model using stan_lmer, we can check the priors by prior_summary function.</span></p><p class="c22"><span class="c10 c30 c29 c13 c34"># Obtain a summary of priors used</span><span class="c9"><br></span><span class="c1">prior_summary</span><span class="c8">(</span><span class="c11 c10">object =</span><span class="c8">&nbsp;M1_stanlmer)</span></p><p class="c22"><span class="c9 c10">## Priors for model &#39;M1_stanlmer&#39; </span><span class="c9"><br></span><span class="c9 c10">## ------</span><span class="c9"><br></span><span class="c9 c10">## Intercept (after predictors centered)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;~ normal(location = 0, scale = 10)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp;**adjusted scale = 0.46</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Auxiliary (sigma)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;~ exponential(rate = 1)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp;**adjusted scale = 0.046 (adjusted rate = 1/adjusted scale)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Covariance</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;~ decov(reg. = 1, conc. = 1, shape = 1, scale = 1)</span><span class="c9"><br></span><span class="c9 c10">## ------</span><span class="c9"><br></span><span class="c9 c10">## See help(&#39;prior_summary.stanreg&#39;) for more details</span></p><p class="c22"><span class="c10 c30 c29 c13 c34"># Obtain SD of outcome</span><span class="c9"><br></span><span class="c1">sd</span><span class="c8">(state</span><span class="c18 c13">$</span><span class="c8">lfpr, </span><span class="c10 c11">na.rm =</span><span class="c8">&nbsp;</span><span class="c10 c30 c13 c34">TRUE</span><span class="c8">)</span></p><p class="c22"><span class="c9 c10">## [1] 0.04555567</span></p><p class="c42"><span class="c23 c28">As seen above, the scales of the priors for </span><img src="images/image7.png"><span class="c23 c28">&nbsp;and </span><img src="images/image8.png"><span class="c26 c23">&nbsp;are set to 0.46 and 0.046 respectively after rescaling.</span></p><p class="c42"><span class="c26 c23">Now we can display a quick summary of the fit from Model 1 using the print method.</span></p><p class="c22"><span class="c10 c30 c29 c13 c34">#Posterior medians and posterior median absolute deviations</span><span class="c9"><br></span><span class="c1">print</span><span class="c8">(M1_stanlmer, </span><span class="c11 c10">digits =</span><span class="c8">&nbsp;</span><span class="c6">2</span><span class="c8">)</span></p><p class="c22"><span class="c9 c10">## stan_lmer</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;family: &nbsp; &nbsp; &nbsp; gaussian [identity]</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;formula: &nbsp; &nbsp; &nbsp;lfpr ~ 1 + (1 | state)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;observations: 2002</span><span class="c9"><br></span><span class="c9 c10">## ------</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Median MAD_SD</span><span class="c9"><br></span><span class="c9 c10">## (Intercept) 0.65 &nbsp; 0.00 &nbsp;</span><span class="c9"><br></span><span class="c9 c10">## sigma &nbsp; &nbsp; &nbsp; 0.03 &nbsp; 0.00 &nbsp;</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Error terms:</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;Groups &nbsp; Name &nbsp; &nbsp; &nbsp; &nbsp;Std.Dev.</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;state &nbsp; &nbsp;(Intercept) 0.0379 &nbsp;</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;Residual &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.0269 &nbsp;</span><span class="c9"><br></span><span class="c9 c10">## Num. levels: state 51 </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Sample avg. posterior predictive distribution of y:</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Median MAD_SD</span><span class="c9"><br></span><span class="c9 c10">## mean_PPD 0.65 &nbsp; 0.00 &nbsp;</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## ------</span><span class="c9"><br></span><span class="c9 c10">## For info on the priors used see help(&#39;prior_summary.stanreg&#39;).</span></p><p class="c22"><span class="c10 c30 c29 c13 c34">#Posterior means, posterior standard deviations, 95% credible intervals and Monte Carlo errors</span><span class="c9"><br></span><span class="c1">summary</span><span class="c8">(M1_stanlmer,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">pars =</span><span class="c8">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c7">&quot;(Intercept)&quot;</span><span class="c8">, </span><span class="c7">&quot;sigma&quot;</span><span class="c8">, </span><span class="c7">&quot;Sigma[state:(Intercept),(Intercept)]&quot;</span><span class="c8">),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">probs =</span><span class="c8">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c6">0.025</span><span class="c8">, </span><span class="c6">0.975</span><span class="c8">),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">digits =</span><span class="c8">&nbsp;</span><span class="c6">2</span><span class="c8">)</span></p><p class="c22"><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Model Info:</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## &nbsp;function: &nbsp; &nbsp; stan_lmer</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;family: &nbsp; &nbsp; &nbsp; gaussian [identity]</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;formula: &nbsp; &nbsp; &nbsp;lfpr ~ 1 + (1 | state)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;algorithm: &nbsp; &nbsp;sampling</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;priors: &nbsp; &nbsp; &nbsp; see help(&#39;prior_summary&#39;)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;sample: &nbsp; &nbsp; &nbsp; 4000 (posterior sample size)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;observations: 2002</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;groups: &nbsp; &nbsp; &nbsp; state (51)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Estimates:</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mean &nbsp; sd &nbsp; 2.5% &nbsp; 97.5%</span><span class="c9"><br></span><span class="c9 c10">## (Intercept) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;0.65 &nbsp; 0.00 0.64 &nbsp; 0.66 &nbsp; </span><span class="c9"><br></span><span class="c9 c10">## sigma &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;0.03 &nbsp; 0.00 0.03 &nbsp; 0.03 &nbsp; </span><span class="c9"><br></span><span class="c9 c10">## Sigma[state:(Intercept),(Intercept)] 0.00 &nbsp; 0.00 0.00 &nbsp; 0.00 &nbsp; </span><span class="c9"><br></span><span class="c9 c10">## Diagnostics:</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mcse Rhat n_eff</span><span class="c9"><br></span><span class="c9 c10">## (Intercept) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;0.00 1.05 &nbsp;101 </span><span class="c9"><br></span><span class="c9 c10">## sigma &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;0.00 1.00 1944 </span><span class="c9"><br></span><span class="c9 c10">## Sigma[state:(Intercept),(Intercept)] 0.00 1.02 &nbsp;201 </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).</span></p><p class="c22"><span class="c10 c30 c29 c13 c34"># Extract the posterior draws for all parameters</span><span class="c9"><br></span><span class="c8">sims &lt;-</span><span class="c7">&nbsp;</span><span class="c1">as.matrix</span><span class="c8">(M1_stanlmer)</span><span class="c9"><br></span><span class="c1">dim</span><span class="c8">(sims)</span></p><p class="c22"><span class="c9 c10">## [1] 4000 &nbsp; 54</span></p><p class="c22"><span class="c8">para_name &lt;-</span><span class="c7">&nbsp;</span><span class="c1">colnames</span><span class="c8">(sims)</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># para_name</span></p><p class="c22"><span class="c10 c30 c29 c13 c34">##Obtaining means, standard deviations, medians and 95% credible intervals.</span><span class="c9"><br><br></span><span class="c10 c30 c29 c13 c34"># Obtain state-level varying intercept a_j</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># draws for overall mean</span><span class="c9"><br></span><span class="c8">mu_a_sims &lt;-</span><span class="c7">&nbsp;</span><span class="c1">as.matrix</span><span class="c8">(M1_stanlmer,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">pars =</span><span class="c8">&nbsp;</span><span class="c7">&quot;(Intercept)&quot;</span><span class="c8">)</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># draws for statel-level error</span><span class="c9"><br></span><span class="c8">u_sims &lt;-</span><span class="c7">&nbsp;</span><span class="c1">as.matrix</span><span class="c8">(M1_stanlmer,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">regex_pars =</span><span class="c8">&nbsp;</span><span class="c7">&quot;b\\[\\(Intercept\\) state\\:&quot;</span><span class="c8">)</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># draws for states&#39; varying intercepts</span><span class="c9"><br></span><span class="c8">a_sims &lt;-</span><span class="c7">&nbsp;</span><span class="c1">as.numeric</span><span class="c8">(mu_a_sims) </span><span class="c18 c13">+</span><span class="c7">&nbsp;</span><span class="c8">u_sims</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># Obtain sigma_y and sigma_alpha^2</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># draws for sigma_y</span><span class="c9"><br></span><span class="c8">s_y_sims &lt;-</span><span class="c7">&nbsp;</span><span class="c1">as.matrix</span><span class="c8">(M1_stanlmer,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">pars =</span><span class="c8">&nbsp;</span><span class="c7">&quot;sigma&quot;</span><span class="c8">)</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># draws for sigma_alpha^2</span><span class="c9"><br></span><span class="c8">s__alpha_sims &lt;-</span><span class="c7">&nbsp;</span><span class="c1">as.matrix</span><span class="c8">(M1_stanlmer,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">pars =</span><span class="c8">&nbsp;</span><span class="c7">&quot;Sigma[state:(Intercept),(Intercept)]&quot;</span><span class="c8">)</span><span class="c9"><br><br><br></span><span class="c10 c30 c29 c13 c34"># Compute mean, SD, median, and 95% credible interval of varying intercepts</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># Posterior mean and SD of each alpha</span><span class="c9"><br></span><span class="c8">a_mean &lt;-</span><span class="c7">&nbsp;</span><span class="c1">apply</span><span class="c8">(</span><span class="c11 c10">X =</span><span class="c8">&nbsp;a_sims,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">MARGIN =</span><span class="c8">&nbsp;</span><span class="c6">2</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">FUN =</span><span class="c8">&nbsp;mean)</span><span class="c9"><br></span><span class="c8">a_sd &lt;-</span><span class="c7">&nbsp;</span><span class="c1">apply</span><span class="c8">(</span><span class="c11 c10">X =</span><span class="c8">&nbsp;a_sims,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">MARGIN =</span><span class="c8">&nbsp;</span><span class="c6">2</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">FUN =</span><span class="c8">&nbsp;sd)</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># posterior mean</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># posterior SD</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># Posterior median and 95% credible interval</span><span class="c9"><br></span><span class="c8">a_quant &lt;-</span><span class="c7">&nbsp;</span><span class="c1">apply</span><span class="c8">(</span><span class="c11 c10">X =</span><span class="c8">&nbsp;a_sims,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">MARGIN =</span><span class="c8">&nbsp;</span><span class="c6">2</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">FUN =</span><span class="c8">&nbsp;quantile,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">probs =</span><span class="c8">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c6">0.025</span><span class="c8">, </span><span class="c6">0.50</span><span class="c8">, </span><span class="c6">0.975</span><span class="c8">))</span><span class="c9"><br></span><span class="c8">a_quant &lt;-</span><span class="c7">&nbsp;</span><span class="c1">data.frame</span><span class="c8">(</span><span class="c1">t</span><span class="c8">(a_quant))</span><span class="c9"><br></span><span class="c1">names</span><span class="c8">(a_quant) &lt;-</span><span class="c7">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c7">&quot;Q2.5&quot;</span><span class="c8">, </span><span class="c7">&quot;Q50&quot;</span><span class="c8">, </span><span class="c7">&quot;Q97.5&quot;</span><span class="c8">)</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># Combine summary statistics of posterior simulation draws</span><span class="c9"><br></span><span class="c8">a_df &lt;-</span><span class="c7">&nbsp;</span><span class="c1">data.frame</span><span class="c8">(a_mean, a_sd, a_quant)</span><span class="c9"><br></span><span class="c1">round</span><span class="c8">(</span><span class="c1">head</span><span class="c8">(a_df), </span><span class="c6">2</span><span class="c8">)</span></p><p class="c22"><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;a_mean a_sd Q2.5 &nbsp;Q50 Q97.5</span><span class="c9"><br></span><span class="c9 c10">## b[(Intercept) state:1] &nbsp; 0.59 &nbsp; &nbsp;0 0.58 0.59 &nbsp;0.60</span><span class="c9"><br></span><span class="c9 c10">## b[(Intercept) state:2] &nbsp; 0.70 &nbsp; &nbsp;0 0.69 0.70 &nbsp;0.70</span><span class="c9"><br></span><span class="c9 c10">## b[(Intercept) state:4] &nbsp; 0.62 &nbsp; &nbsp;0 0.61 0.62 &nbsp;0.63</span><span class="c9"><br></span><span class="c9 c10">## b[(Intercept) state:5] &nbsp; 0.60 &nbsp; &nbsp;0 0.60 0.60 &nbsp;0.61</span><span class="c9"><br></span><span class="c9 c10">## b[(Intercept) state:6] &nbsp; 0.64 &nbsp; &nbsp;0 0.63 0.64 &nbsp;0.65</span><span class="c9"><br></span><span class="c9 c10">## b[(Intercept) state:8] &nbsp; 0.69 &nbsp; &nbsp;0 0.68 0.69 &nbsp;0.70</span></p><p class="c22"><span class="c10 c30 c29 c13 c34"># Sort dataframe containing an estimated alpha&#39;s mean and sd for every school</span><span class="c9"><br></span><span class="c8">a_df &lt;-</span><span class="c7">&nbsp;</span><span class="c8">a_df[</span><span class="c1">order</span><span class="c8">(a_df</span><span class="c18 c13">$</span><span class="c8">a_mean), ]</span><span class="c9"><br></span><span class="c8">a_df</span><span class="c18 c13">$</span><span class="c8">a_rank &lt;-</span><span class="c7">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c6">1</span><span class="c8">&nbsp;</span><span class="c18 c13">:</span><span class="c7">&nbsp;</span><span class="c1">dim</span><span class="c8">(a_df)[</span><span class="c6">1</span><span class="c8">]) &nbsp;</span><span class="c10 c30 c29 c13 c34"># a vector of school rank</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># Plot state-level alphas&#39;s posterior mean and 95% credible interval</span><span class="c9"><br></span><span class="c1">ggplot</span><span class="c8">(</span><span class="c11 c10">data =</span><span class="c8">&nbsp;a_df,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c1">aes</span><span class="c8">(</span><span class="c11 c10">x =</span><span class="c8">&nbsp;a_rank,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">y =</span><span class="c8">&nbsp;a_mean)) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">geom_pointrange</span><span class="c8">(</span><span class="c1">aes</span><span class="c8">(</span><span class="c11 c10">ymin =</span><span class="c8">&nbsp;Q2</span><span class="c6">.5</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">ymax =</span><span class="c8">&nbsp;Q97</span><span class="c6">.5</span><span class="c8">),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">position =</span><span class="c8">&nbsp;</span><span class="c1">position_jitter</span><span class="c8">(</span><span class="c11 c10">width =</span><span class="c8">&nbsp;</span><span class="c6">0.1</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">height =</span><span class="c8">&nbsp;</span><span class="c6">0</span><span class="c8">)) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">geom_hline</span><span class="c8">(</span><span class="c11 c10">yintercept =</span><span class="c8">&nbsp;</span><span class="c1">mean</span><span class="c8">(a_df</span><span class="c18 c13">$</span><span class="c8">a_mean),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">size =</span><span class="c8">&nbsp;</span><span class="c6">0.5</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">col =</span><span class="c8">&nbsp;</span><span class="c7">&quot;red&quot;</span><span class="c8">) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">scale_x_continuous</span><span class="c8">(</span><span class="c7">&quot;Rank&quot;</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">breaks =</span><span class="c8">&nbsp;</span><span class="c1">seq</span><span class="c8">(</span><span class="c11 c10">from =</span><span class="c8">&nbsp;</span><span class="c6">0</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">to =</span><span class="c8">&nbsp;</span><span class="c6">80</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">by =</span><span class="c8">&nbsp;</span><span class="c6">5</span><span class="c8">)) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">scale_y_continuous</span><span class="c8">(</span><span class="c1">expression</span><span class="c8">(</span><span class="c1">paste</span><span class="c8">(</span><span class="c7">&quot;varying intercept, &quot;</span><span class="c8">, alpha[j]))) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">theme_bw</span><span class="c8">( </span><span class="c11 c10">base_family =</span><span class="c8">&nbsp;</span><span class="c7">&quot;serif&quot;</span><span class="c8">)</span></p><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 403.50px; height: 322.80px;"><img alt="" src="images/image30.png" style="width: 403.50px; height: 322.80px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c17"><span class="c19 c9">Fig 3.1.1.1: State-level alphas&#39;s Posterior Mean and 95% Credible Interval<br></span></p><p class="c22"><span class="c10 c30 c29 c13 c34">##Making comparisons between individual states</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># The difference between the two state averages (state #6 California and #36 New York)</span><span class="c9"><br></span><span class="c8">state_diff &lt;-</span><span class="c7">&nbsp;</span><span class="c8">a_sims[, </span><span class="c6">6</span><span class="c8">] </span><span class="c18 c13">-</span><span class="c7">&nbsp;</span><span class="c8">a_sims[, </span><span class="c6">36</span><span class="c8">]</span><span class="c9"><br><br></span><span class="c10 c30 c29 c13 c34"># Investigate differences of two distributions</span><span class="c9"><br></span><span class="c8">mean &lt;-</span><span class="c7">&nbsp;</span><span class="c1">mean</span><span class="c8">(state_diff)</span><span class="c9"><br></span><span class="c8">sd &lt;-</span><span class="c7">&nbsp;</span><span class="c1">sd</span><span class="c8">(state_diff)</span><span class="c9"><br></span><span class="c8">quantile &lt;-</span><span class="c7">&nbsp;</span><span class="c1">quantile</span><span class="c8">(state_diff, </span><span class="c11 c10">probs =</span><span class="c8">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c6">0.025</span><span class="c8">, </span><span class="c6">0.50</span><span class="c8">, </span><span class="c6">0.975</span><span class="c8">))</span><span class="c9"><br></span><span class="c8">quantile &lt;-</span><span class="c7">&nbsp;</span><span class="c1">data.frame</span><span class="c8">(</span><span class="c1">t</span><span class="c8">(quantile))</span><span class="c9"><br></span><span class="c1">names</span><span class="c8">(quantile) &lt;-</span><span class="c7">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c7">&quot;Q2.5&quot;</span><span class="c8">, </span><span class="c7">&quot;Q50&quot;</span><span class="c8">, </span><span class="c7">&quot;Q97.5&quot;</span><span class="c8">)</span><span class="c9"><br></span><span class="c8">diff_df &lt;-</span><span class="c7">&nbsp;</span><span class="c1">data.frame</span><span class="c8">(mean, sd, quantile)</span><span class="c9"><br></span><span class="c1">round</span><span class="c8">(diff_df, </span><span class="c6">6</span><span class="c8">)</span></p><p class="c22"><span class="c9 c10">## &nbsp; &nbsp; &nbsp; mean &nbsp; &nbsp; &nbsp; sd &nbsp; &nbsp; Q2.5 &nbsp; &nbsp; &nbsp;Q50 &nbsp; &nbsp;Q97.5</span><span class="c9"><br></span><span class="c9 c10">## 1 0.053897 0.006047 0.041949 0.053896 0.065881</span></p><p class="c22"><span class="c8">state_diff &lt;-</span><span class="c7">&nbsp;</span><span class="c8">state_diff</span><span class="c18 c13">*</span><span class="c6">100</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># Histogram of the differences</span><span class="c9"><br></span><span class="c1">ggplot</span><span class="c8">(</span><span class="c11 c10">data =</span><span class="c8">&nbsp;</span><span class="c1">data.frame</span><span class="c8">(state_diff),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c1">aes</span><span class="c8">(</span><span class="c11 c10">x =</span><span class="c8">&nbsp;state_diff)) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">geom_histogram</span><span class="c8">(</span><span class="c11 c10">color =</span><span class="c8">&nbsp;</span><span class="c7">&quot;black&quot;</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">fill =</span><span class="c8">&nbsp;</span><span class="c7">&quot;gray&quot;</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">binwidth =</span><span class="c8">&nbsp;</span><span class="c6">0.25</span><span class="c8">) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">scale_x_continuous</span><span class="c8">(</span><span class="c7">&quot;Labor Force Participation Rate diffence between two states: California &amp; New York (*100)&quot;</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">breaks =</span><span class="c8">&nbsp;</span><span class="c1">seq</span><span class="c8">(</span><span class="c11 c10">from =</span><span class="c8">&nbsp;</span><span class="c6">3</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">to =</span><span class="c8">&nbsp;</span><span class="c6">8</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">by =</span><span class="c8">&nbsp;</span><span class="c6">0.5</span><span class="c8">)) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">geom_vline</span><span class="c8">(</span><span class="c11 c10">xintercept =</span><span class="c8">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c1">mean</span><span class="c8">(state_diff),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c1">quantile</span><span class="c8">(state_diff,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">probs =</span><span class="c8">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c6">0.025</span><span class="c8">, </span><span class="c6">0.975</span><span class="c8">))),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">colour =</span><span class="c8">&nbsp;</span><span class="c7">&quot;red&quot;</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">linetype =</span><span class="c8">&nbsp;</span><span class="c7">&quot;longdash&quot;</span><span class="c8">) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">geom_text</span><span class="c8">(</span><span class="c1">aes</span><span class="c8">(</span><span class="c6">5.39</span><span class="c8">, </span><span class="c6">30</span><span class="c8">, </span><span class="c11 c10">label =</span><span class="c8">&nbsp;</span><span class="c7">&quot;mean = 0.0539&quot;</span><span class="c8">),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">color =</span><span class="c8">&nbsp;</span><span class="c7">&quot;red&quot;</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">size =</span><span class="c8">&nbsp;</span><span class="c6">4</span><span class="c8">) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">geom_text</span><span class="c8">(</span><span class="c1">aes</span><span class="c8">(</span><span class="c6">7</span><span class="c8">, </span><span class="c6">50</span><span class="c8">, </span><span class="c11 c10">label =</span><span class="c8">&nbsp;</span><span class="c7">&quot;SD = 0.0060&quot;</span><span class="c8">),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">color =</span><span class="c8">&nbsp;</span><span class="c7">&quot;blue&quot;</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">size =</span><span class="c8">&nbsp;</span><span class="c6">4</span><span class="c8">) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">theme_bw</span><span class="c8">( </span><span class="c11 c10">base_family =</span><span class="c8">&nbsp;</span><span class="c7">&quot;serif&quot;</span><span class="c8">)</span></p><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 425.50px; height: 340.40px;"><img alt="" src="images/image28.png" style="width: 425.50px; height: 340.40px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c17"><span class="c19 c9">Fig 3.1.1.2: Histogram of the differences<br></span></p><p class="c17 c39"><span class="c19 c9"></span></p><p class="c17 c39"><span class="c19 c9"></span></p><p class="c17 c39"><span class="c19 c9"></span></p><p class="c17 c39"><span class="c19 c9"></span></p><p class="c17 c39"><span class="c19 c9"></span></p><p class="c17 c39"><span class="c19 c9"></span></p><p class="c17 c39"><span class="c19 c9"></span></p><p class="c22"><span class="c1">plot</span><span class="c8">(M1_stanlmer, </span><span class="c7">&quot;rhat&quot;</span><span class="c8">)</span></p><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 421.50px; height: 337.59px;"><img alt="" src="images/image29.png" style="width: 421.50px; height: 337.59px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c17"><span class="c19 c9">Fig &nbsp;3.1.1.3</span></p><p class="c22"><span class="c1">plot</span><span class="c8">(M1_stanlmer, </span><span class="c7">&quot;ess&quot;</span><span class="c8">)</span></p><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 423.13px; height: 338.50px;"><img alt="" src="images/image31.png" style="width: 423.13px; height: 338.50px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c17"><span class="c19 c9">Fig 3.1.1.4</span></p><p class="c22"><span class="c8">y_pre &lt;-</span><span class="c7">&nbsp;</span><span class="c1">rep</span><span class="c8">(</span><span class="c10 c30 c13 c34">NA</span><span class="c8">, </span><span class="c1">nrow</span><span class="c8">(state))</span><span class="c9"><br></span><span class="c1">for</span><span class="c8">&nbsp;(i </span><span class="c1">in</span><span class="c8">&nbsp;</span><span class="c6">1</span><span class="c18 c13">:</span><span class="c7">&nbsp;</span><span class="c1">nrow</span><span class="c8">(state)){</span><span class="c9"><br></span><span class="c8">&nbsp; a &lt;-</span><span class="c7">&nbsp;</span><span class="c1">rnorm</span><span class="c8">(</span><span class="c6">1</span><span class="c8">,</span><span class="c6">0.65</span><span class="c8">,</span><span class="c6">0.03</span><span class="c8">)</span><span class="c9"><br></span><span class="c8">&nbsp; y_pre[i] &lt;-</span><span class="c7">&nbsp;</span><span class="c1">rnorm</span><span class="c8">(</span><span class="c6">1</span><span class="c8">,a,</span><span class="c6">0</span><span class="c8">)</span><span class="c9"><br></span><span class="c8">}</span><span class="c9"><br><br></span><span class="c1">library</span><span class="c8">(Metrics)</span></p><p class="c22"><span class="c8">MSE &lt;-</span><span class="c7">&nbsp;</span><span class="c1">round</span><span class="c8">(</span><span class="c1">mse</span><span class="c8">(y_pre,state</span><span class="c18 c13">$</span><span class="c8">lfpr),</span><span class="c6">4</span><span class="c8">)</span><span class="c9"><br></span><span class="c8">MSE</span></p><p class="c22"><span class="c9 c10">## [1] 0.0029</span></p><p class="c42 c39"><span class="c4"></span></p><p class="c20"><span class="c23">From </span><span class="c26 c23">Fig. 3.1.1, we can see that the caterpillar plot shows the fully Bayes estimates for the state varying intercepts in rank order together with their 95% credible intervals. By inserting fitted parameter back to the model, the model get 0.0029 MSE, which is quite small.</span></p><p class="c20"><span class="c23">Furthermore, as California (#6) and New York(#36) are two states with great GDP in U.S., &nbsp;we are interested in the comparison between them. We take the difference between the two vectors of draws </span><img src="images/image9.png"><span class="c26 c23">&nbsp;and investigate the posterior distribution of the difference with descriptive statistics and a histogram.</span></p><p class="c20"><span class="c23">The expected difference comes to 0.0539 with a standard deviation of 0.006 and a wide range of uncertainty (Fig. 3.1.1.2). The 95% credible interval is [0.0419, 0.0659], so we are 95% certain that the true value of the difference between the two states lies within the range given the data. We then evaluate model convergence. The diagnostics which we use to access whether the chains have converged to the posterior distribution are the statistics </span><img src="images/image10.png"><span class="c23">and </span><img src="images/image11.png"><span class="c23">&nbsp;. The </span><img src="images/image10.png"><span class="c23">&nbsp;is the ratio of between-chain variance to within-chain variance. Since the </span><img src="images/image10.png"><span class="c26 c23">&nbsp;is always less than 1.1, all the chains have converged.</span></p><h3 class="c44" id="h.ejybu3qsmboj"><span class="c3"></span></h3><h3 class="c51" id="h.h36s7gi80sud"><span class="c3">3.1.2 Labor Force Participation Rate based on Income</span></h3><h3 class="c40" id="h.otqfc6k1wb0o"><span class="c10 c30 c13">M1_stanlmer &lt;-</span><span class="c7">&nbsp;</span><span class="c1">stan_lmer</span><span class="c10 c30 c13">(</span><span class="c11 c10">formula =</span><span class="c10 c30 c13">&nbsp;lfpr </span><span class="c18 c13">~</span><span class="c7">&nbsp;</span><span class="c6">1</span><span class="c10 c30 c13">&nbsp;</span><span class="c18 c13">+</span><span class="c7">&nbsp;</span><span class="c10 c30 c13">(</span><span class="c6">1</span><span class="c10 c30 c13">&nbsp;</span><span class="c18 c13">|</span><span class="c7">&nbsp;</span><span class="c10 c30 c13">income),</span><span class="c30"><br></span><span class="c10 c30 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">data =</span><span class="c10 c30 c13">&nbsp;income,</span><span class="c30"><br></span><span class="c10 c30 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">seed =</span><span class="c10 c30 c13">&nbsp;</span><span class="c6">349</span><span class="c10 c30 c13">)</span></h3><p class="c22"><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 1).</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Gradient evaluation took 0.000111 seconds</span><span class="c9"><br></span><span class="c9 c10">## 1000 transitions using 10 leapfrog steps per transition would take 1.11 seconds.</span><span class="c9"><br></span><span class="c9 c10">## Adjust your expectations accordingly!</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp; &nbsp;1 / 2000 [ &nbsp;0%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;200 / 2000 [ 10%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;400 / 2000 [ 20%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;600 / 2000 [ 30%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;800 / 2000 [ 40%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1000 / 2000 [ 50%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1001 / 2000 [ 50%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1200 / 2000 [ 60%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1400 / 2000 [ 70%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1600 / 2000 [ 80%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1800 / 2000 [ 90%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 2000 / 2000 [100%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## &nbsp;Elapsed Time: 16.3059 seconds (Warm-up)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3.40846 seconds (Sampling)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;19.7144 seconds (Total)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 2).</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Gradient evaluation took 0.000107 seconds</span><span class="c9"><br></span><span class="c9 c10">## 1000 transitions using 10 leapfrog steps per transition would take 1.07 seconds.</span><span class="c9"><br></span><span class="c9 c10">## Adjust your expectations accordingly!</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp; &nbsp;1 / 2000 [ &nbsp;0%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;200 / 2000 [ 10%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;400 / 2000 [ 20%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;600 / 2000 [ 30%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;800 / 2000 [ 40%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1000 / 2000 [ 50%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1001 / 2000 [ 50%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1200 / 2000 [ 60%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1400 / 2000 [ 70%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1600 / 2000 [ 80%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1800 / 2000 [ 90%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 2000 / 2000 [100%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## &nbsp;Elapsed Time: 16.0588 seconds (Warm-up)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3.40529 seconds (Sampling)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;19.4641 seconds (Total)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 3).</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Gradient evaluation took 0.000105 seconds</span><span class="c9"><br></span><span class="c9 c10">## 1000 transitions using 10 leapfrog steps per transition would take 1.05 seconds.</span><span class="c9"><br></span><span class="c9 c10">## Adjust your expectations accordingly!</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp; &nbsp;1 / 2000 [ &nbsp;0%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;200 / 2000 [ 10%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;400 / 2000 [ 20%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;600 / 2000 [ 30%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;800 / 2000 [ 40%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1000 / 2000 [ 50%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1001 / 2000 [ 50%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1200 / 2000 [ 60%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1400 / 2000 [ 70%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1600 / 2000 [ 80%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1800 / 2000 [ 90%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 2000 / 2000 [100%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## &nbsp;Elapsed Time: 12.991 seconds (Warm-up)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3.44292 seconds (Sampling)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;16.4339 seconds (Total)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 4).</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Gradient evaluation took 0.000107 seconds</span><span class="c9"><br></span><span class="c9 c10">## 1000 transitions using 10 leapfrog steps per transition would take 1.07 seconds.</span><span class="c9"><br></span><span class="c9 c10">## Adjust your expectations accordingly!</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp; &nbsp;1 / 2000 [ &nbsp;0%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;200 / 2000 [ 10%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;400 / 2000 [ 20%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;600 / 2000 [ 30%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: &nbsp;800 / 2000 [ 40%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1000 / 2000 [ 50%] &nbsp;(Warmup)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1001 / 2000 [ 50%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1200 / 2000 [ 60%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1400 / 2000 [ 70%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1600 / 2000 [ 80%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 1800 / 2000 [ 90%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## Iteration: 2000 / 2000 [100%] &nbsp;(Sampling)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## &nbsp;Elapsed Time: 15.9128 seconds (Warm-up)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3.39316 seconds (Sampling)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;19.306 seconds (Total)</span></p><p class="c22"><span class="c10 c30 c29 c13 c34"># Obtain a summary of priors used</span><span class="c9"><br></span><span class="c1">prior_summary</span><span class="c8">(</span><span class="c11 c10">object =</span><span class="c8">&nbsp;M1_stanlmer)</span></p><p class="c22"><span class="c9 c10">## Priors for model &#39;M1_stanlmer&#39; </span><span class="c9"><br></span><span class="c9 c10">## ------</span><span class="c9"><br></span><span class="c9 c10">## Intercept (after predictors centered)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;~ normal(location = 0, scale = 10)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp;**adjusted scale = 1.38</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Auxiliary (sigma)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;~ exponential(rate = 1)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp;**adjusted scale = 0.14 (adjusted rate = 1/adjusted scale)</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Covariance</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;~ decov(reg. = 1, conc. = 1, shape = 1, scale = 1)</span><span class="c9"><br></span><span class="c9 c10">## ------</span><span class="c9"><br></span><span class="c9 c10">## See help(&#39;prior_summary.stanreg&#39;) for more details</span></p><p class="c22"><span class="c10 c30 c29 c13 c34"># Obtain SD of outcome</span><span class="c9"><br></span><span class="c1">sd</span><span class="c8">(income</span><span class="c18 c13">$</span><span class="c8">lfpr, </span><span class="c11 c10">na.rm =</span><span class="c8">&nbsp;</span><span class="c10 c30 c13 c34">TRUE</span><span class="c8">)</span></p><p class="c22"><span class="c9 c10">## [1] 0.1379202</span></p><p class="c22"><span class="c10 c30 c29 c13 c34">#Posterior medians and posterior median absolute deviations</span><span class="c9"><br></span><span class="c1">print</span><span class="c8">(M1_stanlmer, </span><span class="c11 c10">digits =</span><span class="c8">&nbsp;</span><span class="c6">2</span><span class="c8">)</span></p><p class="c22"><span class="c9 c10">## stan_lmer</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;family: &nbsp; &nbsp; &nbsp; gaussian [identity]</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;formula: &nbsp; &nbsp; &nbsp;lfpr ~ 1 + (1 | income)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;observations: 1234</span><span class="c9"><br></span><span class="c9 c10">## ------</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Median MAD_SD</span><span class="c9"><br></span><span class="c9 c10">## (Intercept) 0.98 &nbsp; 0.01 &nbsp;</span><span class="c9"><br></span><span class="c9 c10">## sigma &nbsp; &nbsp; &nbsp; 0.07 &nbsp; 0.00 &nbsp;</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Error terms:</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;Groups &nbsp; Name &nbsp; &nbsp; &nbsp; &nbsp;Std.Dev.</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;income &nbsp; (Intercept) 0.0763 &nbsp;</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;Residual &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.0669 &nbsp;</span><span class="c9"><br></span><span class="c9 c10">## Num. levels: income 114 </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Sample avg. posterior predictive distribution of y:</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Median MAD_SD</span><span class="c9"><br></span><span class="c9 c10">## mean_PPD 0.96 &nbsp; 0.00 &nbsp;</span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## ------</span><span class="c9"><br></span><span class="c9 c10">## For info on the priors used see help(&#39;prior_summary.stanreg&#39;).</span></p><p class="c22"><span class="c10 c30 c29 c13 c34">#Posterior means, posterior standard deviations, 95% credible intervals and Monte Carlo errors</span><span class="c9"><br></span><span class="c1">summary</span><span class="c8">(M1_stanlmer,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">pars =</span><span class="c8">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c7">&quot;(Intercept)&quot;</span><span class="c8">, </span><span class="c7">&quot;sigma&quot;</span><span class="c8">, </span><span class="c7">&quot;Sigma[income:(Intercept),(Intercept)]&quot;</span><span class="c8">),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">probs =</span><span class="c8">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c6">0.025</span><span class="c8">, </span><span class="c6">0.975</span><span class="c8">),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">digits =</span><span class="c8">&nbsp;</span><span class="c6">2</span><span class="c8">)</span></p><p class="c22"><span class="c9 c10">## Model Info:</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;function: &nbsp; &nbsp; stan_lmer</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;family: &nbsp; &nbsp; &nbsp; gaussian [identity]</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;formula: &nbsp; &nbsp; &nbsp;lfpr ~ 1 + (1 | income)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;algorithm: &nbsp; &nbsp;sampling</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;priors: &nbsp; &nbsp; &nbsp; see help(&#39;prior_summary&#39;)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;sample: &nbsp; &nbsp; &nbsp; 4000 (posterior sample size)</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;observations: 1234</span><span class="c9"><br></span><span class="c9 c10">## &nbsp;groups: &nbsp; &nbsp; &nbsp; income (114)</span><span class="c9"><br></span><span class="c9 c10">## Estimates:</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mean &nbsp; sd &nbsp; 2.5% &nbsp; 97.5%</span><span class="c9"><br></span><span class="c9 c10">## (Intercept) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.98 &nbsp; 0.01 0.96 &nbsp; 0.99 &nbsp; </span><span class="c9"><br></span><span class="c9 c10">## sigma &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.07 &nbsp; 0.00 0.06 &nbsp; 0.07 &nbsp; </span><span class="c9"><br></span><span class="c9 c10">## Sigma[income:(Intercept),(Intercept)] 0.01 &nbsp; 0.00 0.00 &nbsp; 0.01 &nbsp; </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## Diagnostics:</span><span class="c9"><br></span><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mcse Rhat n_eff</span><span class="c9"><br></span><span class="c9 c10">## (Intercept) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 1.01 &nbsp;337 </span><span class="c9"><br></span><span class="c9 c10">## sigma &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.00 1.00 4000 </span><span class="c9"><br></span><span class="c9 c10">## Sigma[income:(Intercept),(Intercept)] 0.00 1.00 1102 </span><span class="c9"><br></span><span class="c9 c10">## </span><span class="c9"><br></span><span class="c9 c10">## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).</span></p><p class="c22"><span class="c10 c30 c29 c13 c34"># Extract the posterior draws for all parameters</span><span class="c9"><br></span><span class="c8">sims &lt;-</span><span class="c7">&nbsp;</span><span class="c1">as.matrix</span><span class="c8">(M1_stanlmer)</span><span class="c9"><br></span><span class="c1">dim</span><span class="c8">(sims)</span></p><p class="c22"><span class="c9 c10">## [1] 4000 &nbsp;117</span></p><p class="c22"><span class="c8">para_name &lt;-</span><span class="c7">&nbsp;</span><span class="c1">colnames</span><span class="c8">(sims)</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># para_name</span></p><p class="c22"><span class="c10 c30 c29 c13 c34">##Obtaining means, standard deviations, medians and 95% credible intervals.</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># Obtain income-level varying intercept a_j</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># draws for overall mean</span><span class="c9"><br></span><span class="c8">mu_a_sims &lt;-</span><span class="c7">&nbsp;</span><span class="c1">as.matrix</span><span class="c8">(M1_stanlmer,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">pars =</span><span class="c8">&nbsp;</span><span class="c7">&quot;(Intercept)&quot;</span><span class="c8">)</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># draws for income-level error</span><span class="c9"><br></span><span class="c8">u_sims &lt;-</span><span class="c7">&nbsp;</span><span class="c1">as.matrix</span><span class="c8">(M1_stanlmer,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">regex_pars =</span><span class="c8">&nbsp;</span><span class="c7">&quot;b\\[\\(Intercept\\) income\\:&quot;</span><span class="c8">)</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># draws for income&#39;s varying intercepts</span><span class="c9"><br></span><span class="c8">a_sims &lt;-</span><span class="c7">&nbsp;</span><span class="c1">as.numeric</span><span class="c8">(mu_a_sims) </span><span class="c18 c13">+</span><span class="c7">&nbsp;</span><span class="c8">u_sims</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># Obtain sigma_y and sigma_alpha^2</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># draws for sigma_y</span><span class="c9"><br></span><span class="c8">s_y_sims &lt;-</span><span class="c7">&nbsp;</span><span class="c1">as.matrix</span><span class="c8">(M1_stanlmer,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">pars =</span><span class="c8">&nbsp;</span><span class="c7">&quot;sigma&quot;</span><span class="c8">)</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># draws for sigma_alpha^2</span><span class="c9"><br></span><span class="c8">s__alpha_sims &lt;-</span><span class="c7">&nbsp;</span><span class="c1">as.matrix</span><span class="c8">(M1_stanlmer,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">pars =</span><span class="c8">&nbsp;</span><span class="c7">&quot;Sigma[income:(Intercept),(Intercept)]&quot;</span><span class="c8">)</span><span class="c9"><br><br></span><span class="c10 c30 c29 c13 c34"># Compute mean, SD, median, and 95% credible interval of varying intercepts</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># Posterior mean and SD of each alpha</span><span class="c9"><br></span><span class="c8">a_mean &lt;-</span><span class="c7">&nbsp;</span><span class="c1">apply</span><span class="c8">(</span><span class="c11 c10">X =</span><span class="c8">&nbsp;a_sims,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">MARGIN =</span><span class="c8">&nbsp;</span><span class="c6">2</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">FUN =</span><span class="c8">&nbsp;mean)</span><span class="c9"><br></span><span class="c8">a_sd &lt;-</span><span class="c7">&nbsp;</span><span class="c1">apply</span><span class="c8">(</span><span class="c11 c10">X =</span><span class="c8">&nbsp;a_sims,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">MARGIN =</span><span class="c8">&nbsp;</span><span class="c6">2</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">FUN =</span><span class="c8">&nbsp;sd)</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># posterior mean</span><span class="c30">&nbsp;/ </span><span class="c10 c30 c29 c13 c34">SD</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># Posterior median and 95% credible interval</span><span class="c9"><br></span><span class="c8">a_quant &lt;-</span><span class="c7">&nbsp;</span><span class="c1">apply</span><span class="c8">(</span><span class="c11 c10">X =</span><span class="c8">&nbsp;a_sims,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">MARGIN =</span><span class="c8">&nbsp;</span><span class="c6">2</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">FUN =</span><span class="c8">&nbsp;quantile,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">probs =</span><span class="c8">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c6">0.025</span><span class="c8">, </span><span class="c6">0.50</span><span class="c8">, </span><span class="c6">0.975</span><span class="c8">))</span><span class="c9"><br></span><span class="c8">a_quant &lt;-</span><span class="c7">&nbsp;</span><span class="c1">data.frame</span><span class="c8">(</span><span class="c1">t</span><span class="c8">(a_quant))</span><span class="c9"><br></span><span class="c1">names</span><span class="c8">(a_quant) &lt;-</span><span class="c7">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c7">&quot;Q2.5&quot;</span><span class="c8">, </span><span class="c7">&quot;Q50&quot;</span><span class="c8">, </span><span class="c7">&quot;Q97.5&quot;</span><span class="c8">)</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># Combine summary statistics of posterior simulation draws</span><span class="c9"><br></span><span class="c8">a_df &lt;-</span><span class="c7">&nbsp;</span><span class="c1">data.frame</span><span class="c8">(a_mean, a_sd, a_quant)</span><span class="c9"><br></span><span class="c1">round</span><span class="c8">(</span><span class="c1">head</span><span class="c8">(a_df), </span><span class="c6">2</span><span class="c8">)</span></p><p class="c22"><span class="c9 c10">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; a_mean a_sd Q2.5 &nbsp;Q50 Q97.5</span><span class="c9"><br></span><span class="c9 c10">## b[(Intercept) income:0] &nbsp; 0.32 0.01 0.30 0.32 &nbsp;0.34</span><span class="c9"><br></span><span class="c9 c10">## b[(Intercept) income:1] &nbsp; 0.92 0.01 0.90 0.92 &nbsp;0.94</span><span class="c9"><br></span><span class="c9 c10">## b[(Intercept) income:2] &nbsp; 0.97 0.01 0.95 0.97 &nbsp;0.99</span><span class="c9"><br></span><span class="c9 c10">## b[(Intercept) income:3] &nbsp; 0.98 0.01 0.96 0.98 &nbsp;1.00</span><span class="c9"><br></span><span class="c9 c10">## b[(Intercept) income:4] &nbsp; 0.98 0.01 0.96 0.98 &nbsp;1.00</span><span class="c9"><br></span><span class="c9 c10">## b[(Intercept) income:5] &nbsp; 0.98 0.01 0.96 0.98 &nbsp;1.00</span></p><p class="c22"><span class="c10 c30 c29 c13 c34"># Sort dataframe containing an estimated alpha&#39;s mean and sd for every school</span><span class="c9"><br></span><span class="c8">a_df &lt;-</span><span class="c7">&nbsp;</span><span class="c8">a_df[</span><span class="c1">order</span><span class="c8">(a_df</span><span class="c18 c13">$</span><span class="c8">a_mean), ]</span><span class="c9"><br></span><span class="c8">a_df</span><span class="c18 c13">$</span><span class="c8">a_rank &lt;-</span><span class="c7">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c6">1</span><span class="c8">&nbsp;</span><span class="c18 c13">:</span><span class="c7">&nbsp;</span><span class="c1">dim</span><span class="c8">(a_df)[</span><span class="c6">1</span><span class="c8">]) &nbsp;</span><span class="c10 c30 c29 c13 c34"># a vector of school rank</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># Plot income-level alphas&#39;s posterior mean and 95% credible interval</span><span class="c9"><br></span><span class="c1">ggplot</span><span class="c8">(</span><span class="c11 c10">data =</span><span class="c8">&nbsp;a_df,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c1">aes</span><span class="c8">(</span><span class="c11 c10">x =</span><span class="c8">&nbsp;a_rank,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">y =</span><span class="c8">&nbsp;a_mean)) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">geom_pointrange</span><span class="c8">(</span><span class="c1">aes</span><span class="c8">(</span><span class="c11 c10">ymin =</span><span class="c8">&nbsp;Q2</span><span class="c6">.5</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">ymax =</span><span class="c8">&nbsp;Q97</span><span class="c6">.5</span><span class="c8">),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">position =</span><span class="c8">&nbsp;</span><span class="c1">position_jitter</span><span class="c8">(</span><span class="c11 c10">width =</span><span class="c8">&nbsp;</span><span class="c6">0.1</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">height =</span><span class="c8">&nbsp;</span><span class="c6">0</span><span class="c8">)) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">geom_hline</span><span class="c8">(</span><span class="c11 c10">yintercept =</span><span class="c8">&nbsp;</span><span class="c1">mean</span><span class="c8">(a_df</span><span class="c18 c13">$</span><span class="c8">a_mean),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">size =</span><span class="c8">&nbsp;</span><span class="c6">0.5</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">col =</span><span class="c8">&nbsp;</span><span class="c7">&quot;red&quot;</span><span class="c8">) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">scale_x_continuous</span><span class="c8">(</span><span class="c7">&quot;Rank&quot;</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">breaks =</span><span class="c8">&nbsp;</span><span class="c1">seq</span><span class="c8">(</span><span class="c11 c10">from =</span><span class="c8">&nbsp;</span><span class="c6">0</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">to =</span><span class="c8">&nbsp;</span><span class="c6">80</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">by =</span><span class="c8">&nbsp;</span><span class="c6">5</span><span class="c8">)) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">scale_y_continuous</span><span class="c8">(</span><span class="c1">expression</span><span class="c8">(</span><span class="c1">paste</span><span class="c8">(</span><span class="c7">&quot;varying intercept, &quot;</span><span class="c8">, alpha[j]))) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">theme_bw</span><span class="c8">( </span><span class="c11 c10">base_family =</span><span class="c8">&nbsp;</span><span class="c7">&quot;serif&quot;</span><span class="c8">)</span></p><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 369.00px; height: 274.50px;"><img alt="" src="images/image32.png" style="width: 369.00px; height: 274.50px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c17"><span class="c19 c9">Fig 3.1.2.1: Income-level Alphas&#39;s Posterior Mean and 95% Credible Interval<br></span></p><p class="c22"><span class="c10 c30 c29 c13 c34">##Making comparisons between individual income level</span><span class="c9"><br></span><span class="c10 c30 c29 c13 c34"># The difference between the two income averages (income #10,000 and #100,000)</span><span class="c9"><br></span><span class="c8">income_diff &lt;-</span><span class="c7">&nbsp;</span><span class="c8">a_sims[, </span><span class="c6">1</span><span class="c8">] </span><span class="c18 c13">-</span><span class="c7">&nbsp;</span><span class="c8">a_sims[, </span><span class="c6">10</span><span class="c8">]</span><span class="c9"><br><br></span><span class="c10 c30 c29 c13 c34"># Investigate differences of two distributions</span><span class="c9"><br></span><span class="c8">mean &lt;-</span><span class="c7">&nbsp;</span><span class="c1">mean</span><span class="c8">(income_diff)</span><span class="c9"><br></span><span class="c8">sd &lt;-</span><span class="c7">&nbsp;</span><span class="c1">sd</span><span class="c8">(income_diff)</span><span class="c9"><br></span><span class="c8">quantile &lt;-</span><span class="c7">&nbsp;</span><span class="c1">quantile</span><span class="c8">(income_diff, </span><span class="c11 c10">probs =</span><span class="c8">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c6">0.025</span><span class="c8">, </span><span class="c6">0.50</span><span class="c8">, </span><span class="c6">0.975</span><span class="c8">))</span><span class="c9"><br></span><span class="c8">quantile &lt;-</span><span class="c7">&nbsp;</span><span class="c1">data.frame</span><span class="c8">(</span><span class="c1">t</span><span class="c8">(quantile))</span><span class="c9"><br></span><span class="c1">names</span><span class="c8">(quantile) &lt;-</span><span class="c7">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c7">&quot;Q2.5&quot;</span><span class="c8">, </span><span class="c7">&quot;Q50&quot;</span><span class="c8">, </span><span class="c7">&quot;Q97.5&quot;</span><span class="c8">)</span><span class="c9"><br></span><span class="c8">diff_df &lt;-</span><span class="c7">&nbsp;</span><span class="c1">data.frame</span><span class="c8">(mean, sd, quantile)</span><span class="c9"><br></span><span class="c1">round</span><span class="c8">(diff_df, </span><span class="c6">2</span><span class="c8">)</span></p><p class="c22"><span class="c9 c10">## &nbsp; &nbsp;mean &nbsp; sd Q2.5 &nbsp; Q50 Q97.5</span><span class="c9"><br></span><span class="c9 c10">## 1 -0.67 0.02 -0.7 -0.67 -0.64</span></p><p class="c22"><span class="c10 c30 c29 c13 c34">#Labor Force Participation Rate diffence between two group of people with yearly income between 10,000 to 20,000 and 100,000 to 110,000</span><span class="c9"><br></span><span class="c1">ggplot</span><span class="c8">(</span><span class="c11 c10">data =</span><span class="c8">&nbsp;</span><span class="c1">data.frame</span><span class="c8">(income_diff),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c1">aes</span><span class="c8">(</span><span class="c11 c10">x =</span><span class="c8">&nbsp;income_diff)) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">geom_histogram</span><span class="c8">(</span><span class="c11 c10">color =</span><span class="c8">&nbsp;</span><span class="c7">&quot;black&quot;</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">fill =</span><span class="c8">&nbsp;</span><span class="c7">&quot;gray&quot;</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">binwidth =</span><span class="c8">&nbsp;</span><span class="c6">0.01</span><span class="c8">) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">scale_x_continuous</span><span class="c8">(</span><span class="c7">&quot;Labor Force Participation Rate diffence via income&quot;</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">breaks =</span><span class="c8">&nbsp;</span><span class="c1">seq</span><span class="c8">(</span><span class="c11 c10">from =</span><span class="c8">&nbsp;</span><span class="c6">-0.8</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">to =</span><span class="c8">&nbsp;</span><span class="c6">-0.5</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">by =</span><span class="c8">&nbsp;</span><span class="c6">0.05</span><span class="c8">)) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">geom_vline</span><span class="c8">(</span><span class="c11 c10">xintercept =</span><span class="c8">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c1">mean</span><span class="c8">(income_diff),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c1">quantile</span><span class="c8">(income_diff,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">probs =</span><span class="c8">&nbsp;</span><span class="c1">c</span><span class="c8">(</span><span class="c6">0.025</span><span class="c8">, </span><span class="c6">0.975</span><span class="c8">))),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">colour =</span><span class="c8">&nbsp;</span><span class="c7">&quot;red&quot;</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c11 c10">linetype =</span><span class="c8">&nbsp;</span><span class="c7">&quot;longdash&quot;</span><span class="c8">) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">geom_text</span><span class="c8">(</span><span class="c1">aes</span><span class="c8">(</span><span class="c18 c13">-</span><span class="c6">0.6665</span><span class="c8">, </span><span class="c6">50</span><span class="c8">, </span><span class="c11 c10">label =</span><span class="c8">&nbsp;</span><span class="c7">&quot;mean = -0.6665&quot;</span><span class="c8">),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">color =</span><span class="c8">&nbsp;</span><span class="c7">&quot;red&quot;</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">size =</span><span class="c8">&nbsp;</span><span class="c6">4</span><span class="c8">) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">geom_text</span><span class="c8">(</span><span class="c1">aes</span><span class="c8">(</span><span class="c18 c13">-</span><span class="c6">0.62</span><span class="c8">, </span><span class="c6">100</span><span class="c8">, </span><span class="c11 c10">label =</span><span class="c8">&nbsp;</span><span class="c7">&quot;SD = 0.0159&quot;</span><span class="c8">),</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">color =</span><span class="c8">&nbsp;</span><span class="c7">&quot;blue&quot;</span><span class="c8">,</span><span class="c9"><br></span><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c11 c10">size =</span><span class="c8">&nbsp;</span><span class="c6">4</span><span class="c8">) </span><span class="c18 c13">+</span><span class="c9"><br></span><span class="c7">&nbsp; </span><span class="c1">theme_bw</span><span class="c8">( </span><span class="c11 c10">base_family =</span><span class="c8">&nbsp;</span><span class="c7">&quot;serif&quot;</span><span class="c8">)</span></p><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 371.00px; height: 278.00px;"><img alt="" src="images/image33.png" style="width: 371.00px; height: 278.00px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c17"><span class="c30">Fig 3.1.2.2: Histogram of the differences<br></span></p><p class="c22"><span class="c1">plot</span><span class="c8">(M1_stanlmer, </span><span class="c7">&quot;rhat&quot;</span><span class="c8">)</span></p><p class="c45"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 435.70px; height: 350.50px;"><img alt="" src="images/image37.png" style="width: 435.70px; height: 350.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c17"><span class="c19 c9">Fig. 3.1.2.3</span></p><p class="c22"><span class="c1">plot</span><span class="c8">(M1_stanlmer, </span><span class="c7">&quot;ess&quot;</span><span class="c8">)</span></p><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 441.50px; height: 353.00px;"><img alt="" src="images/image35.png" style="width: 441.50px; height: 353.00px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c17"><span class="c19 c9">Fig. 3.1.2.4</span></p><p class="c22"><span class="c8">y_pre &lt;-</span><span class="c7">&nbsp;</span><span class="c1">rep</span><span class="c8">(</span><span class="c10 c30 c13 c34">NA</span><span class="c8">, </span><span class="c1">nrow</span><span class="c8">(income))</span><span class="c9"><br></span><span class="c1">for</span><span class="c8">&nbsp;(i </span><span class="c1">in</span><span class="c8">&nbsp;</span><span class="c6">1</span><span class="c18 c13">:</span><span class="c7">&nbsp;</span><span class="c1">nrow</span><span class="c8">(income)){</span><span class="c9"><br></span><span class="c8">&nbsp; a &lt;-</span><span class="c7">&nbsp;</span><span class="c1">rnorm</span><span class="c8">(</span><span class="c6">1</span><span class="c8">,</span><span class="c6">0.98</span><span class="c8">,</span><span class="c6">0.07</span><span class="c8">)</span><span class="c9"><br></span><span class="c8">&nbsp; y_pre[i] &lt;-</span><span class="c7">&nbsp;</span><span class="c1">rnorm</span><span class="c8">(</span><span class="c6">1</span><span class="c8">,a,</span><span class="c6">0.01</span><span class="c8">)</span><span class="c9"><br></span><span class="c8">}</span></p><p class="c17 c39"><span class="c4"></span></p><p class="c20"><span class="c23">We can also see the plot in Fig 3.1.2.1 shows the fully Bayes estimates for the income varying intercepts in rank together with their 95% credible intervals. In addition, Fig 3.1.2.2 shows that the expected difference between income group from 10,000 to 20,000 and group from 100,000 to 110,000 comes to -0.67 with a standard deviation of 0.02 and a wide range of uncertainty. The 95% credible interval is [-0.7, -0.64], so we are 95% certain that the true value of the difference between the two levels of income lies within the range given the data. From the </span><img src="images/image10.png"><span class="c23">, we can also see that the income model has converged since the distribution of </span><img src="images/image10.png"><span class="c26 c23">&nbsp;is less than 1.1.</span></p><p class="c20"><span class="c26 c23">Above two simple models both show that state and income fit the model for labor force participation rate pretty well, but income offers more concrete prediction results. </span></p><p class="c22 c39"><span class="c4"></span></p><p class="c22 c39"><span class="c4"></span></p><h2 class="c40" id="h.2s8eyo1"><span class="c32 c12 c46 c28">3.2 Varying intercept Model with a Single Predictor</span></h2><p class="c22 c31 c39"><span class="c26 c23"></span></p><p class="c22 c31"><span class="c26 c23">To study the relationship between both variables (state &amp; income) with labor force participation rate, we are going to extend the varying-intercept models by including an indicator variable. </span></p><p class="c22 c31"><span class="c23">The varying intercept model with one predictor at the state level can be written as </span><img src="images/image12.png"><span class="c23">&nbsp;and </span><img src="images/image13.png"><span class="c23">. The equation of the average regression line across incomes is </span><img src="images/image14.png"><span class="c23">. The regression lines for specific incomes will be parallel to the average regression line( having the same slope </span><img src="images/image15.png"><span class="c23">), but differ in terms of its intercept </span><img src="images/image6.png"><span class="c23">. We use noninformative prior distributions for the hyperparameters (</span><img src="images/image7.png"><span class="c23">and </span><img src="images/image16.png"><span class="c23">) as specified in the varying intercept model with no predictors. Additionally, the regression coefficient </span><img src="images/image15.png"><span class="c23 c26">is given normal prior distributions with mean 0 and standard deviation 100. This states, roughly, that we expect this coefficient to be in the range (&minus;100,100), and if the ML estimate is in this range, the prior distribution is providing very little information for the inference.</span></p><p class="c22"><span class="c5 c13">M2_stanlmer &lt;-</span><span class="c2">&nbsp;</span><span class="c1 c16">stan_lmer</span><span class="c5 c13">(</span><span class="c11 c10 c16">formula =</span><span class="c5 c13">&nbsp;lfpr </span><span class="c18 c16 c13">~</span><span class="c2">&nbsp;</span><span class="c5 c13">state </span><span class="c18 c16 c13">+</span><span class="c2">&nbsp;</span><span class="c5 c13">(</span><span class="c6 c16">1</span><span class="c5 c13">&nbsp;</span><span class="c18 c16 c13">|</span><span class="c2">&nbsp;</span><span class="c5 c13">income),</span><span class="c5"><br></span><span class="c5 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c16 c11 c10">data =</span><span class="c5 c13">&nbsp;new_state_income ,</span><span class="c5"><br></span><span class="c5 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c16 c11 c10">prior =</span><span class="c5 c13">&nbsp;</span><span class="c1 c16">normal</span><span class="c5 c13">(</span><span class="c16 c11 c10">location =</span><span class="c5 c13">&nbsp;</span><span class="c6 c16">0</span><span class="c5 c13">,</span><span class="c5"><br></span><span class="c5 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c16 c11 c10">scale =</span><span class="c5 c13">&nbsp;</span><span class="c6 c16">100</span><span class="c5 c13">,</span><span class="c5"><br></span><span class="c5 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c16 c11 c10">autoscale =</span><span class="c5 c13">&nbsp;</span><span class="c16 c10 c30 c13 c34">FALSE</span><span class="c5 c13">),</span><span class="c16 c11 c10">prior_intercept =</span><span class="c5 c13">&nbsp;</span><span class="c1 c16">normal</span><span class="c5 c13">(</span><span class="c16 c11 c10">location =</span><span class="c5 c13">&nbsp;</span><span class="c6 c16">0</span><span class="c5 c13">,</span><span class="c16 c11 c10">scale =</span><span class="c5 c13">&nbsp;</span><span class="c6 c16">100</span><span class="c5 c13">,</span><span class="c16 c11 c10">autoscale =</span><span class="c5 c13">&nbsp;</span><span class="c16 c10 c30 c13 c34">FALSE</span><span class="c5 c13">),</span><span class="c16 c11 c10">seed =</span><span class="c5 c13">&nbsp;</span><span class="c6 c16">349</span><span class="c5 c13">)</span></p><p class="c22"><span class="c1 c16">prior_summary</span><span class="c5 c13">(</span><span class="c16 c11 c10">object =</span><span class="c5 c13">&nbsp;M2_stanlmer)</span></p><p class="c22"><span class="c5 c13">## Priors for model &#39;M2_stanlmer&#39; </span><span class="c5"><br></span><span class="c5 c13">## ------</span><span class="c5"><br></span><span class="c5 c13">## Intercept (after predictors centered)</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;~ normal(location = 0, scale = 100)</span><span class="c5"><br></span><span class="c5 c13">## </span><span class="c5"><br></span><span class="c5 c13">## Coefficients</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;~ normal(location = 0, scale = 100)</span><span class="c5"><br></span><span class="c5 c13">## </span><span class="c5"><br></span><span class="c5 c13">## Auxiliary (sigma)</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;~ exponential(rate = 1)</span><span class="c5"><br></span><span class="c5 c13">## &nbsp; &nbsp; &nbsp;**adjusted scale = 0.17 (adjusted rate = 1/adjusted scale)</span><span class="c5"><br></span><span class="c5 c13">## </span><span class="c5"><br></span><span class="c5 c13">## Covariance</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;~ decov(reg. = 1, conc. = 1, shape = 1, scale = 1)</span><span class="c5"><br></span><span class="c5 c13">## ------</span><span class="c5"><br></span><span class="c5 c13">## See help(&#39;prior_summary.stanreg&#39;) for more details</span></p><p class="c22"><span class="c5 c13">M2_stanlmer</span></p><p class="c22"><span class="c5 c13">## stan_lmer</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;family: &nbsp; &nbsp; &nbsp; gaussian [identity]</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;formula: &nbsp; &nbsp; &nbsp;lfpr ~ state + (1 | income)</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;observations: 1000</span><span class="c5"><br></span><span class="c5 c13">## ------</span><span class="c5"><br></span><span class="c5 c13">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Median MAD_SD</span><span class="c5"><br></span><span class="c5 c13">## (Intercept) 1.0 &nbsp; &nbsp;0.0 &nbsp; </span><span class="c5"><br></span><span class="c5 c13">## state &nbsp; &nbsp; &nbsp; 0.0 &nbsp; &nbsp;0.0 &nbsp; </span><span class="c5"><br></span><span class="c5 c13">## </span><span class="c5"><br></span><span class="c5 c13">## Auxiliary parameter(s):</span><span class="c5"><br></span><span class="c5 c13">## &nbsp; &nbsp; &nbsp; Median MAD_SD</span><span class="c5"><br></span><span class="c5 c13">## sigma 0.1 &nbsp; &nbsp;0.0 &nbsp; </span><span class="c5"><br></span><span class="c5 c13">## </span><span class="c5"><br></span><span class="c5 c13">## Error terms:</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;Groups &nbsp; Name &nbsp; &nbsp; &nbsp; &nbsp;Std.Dev.</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;income &nbsp; (Intercept) 0.095 &nbsp; </span><span class="c5"><br></span><span class="c5 c13">## &nbsp;Residual &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.065 &nbsp; </span><span class="c5"><br></span><span class="c5 c13">## Num. levels: income 68 </span><span class="c5"><br></span><span class="c5 c13">## </span><span class="c5"><br></span><span class="c5 c13">## Sample avg. posterior predictive distribution of y:</span><span class="c5"><br></span><span class="c5 c13">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Median MAD_SD</span><span class="c5"><br></span><span class="c5 c13">## mean_PPD 0.9 &nbsp; &nbsp;0.0 &nbsp; </span><span class="c5"><br></span><span class="c5 c13">## </span><span class="c5"><br></span><span class="c5 c13">## ------</span><span class="c5"><br></span><span class="c5 c13">## * For help interpreting the printed output see ?print.stanreg</span><span class="c5"><br></span><span class="c5 c13">## * For info on the priors used see ?prior_summary.stanreg</span></p><p class="c22 c39"><span class="c4"></span></p><h2 class="c40" id="h.3rdcrjn"><span class="c32 c12 c46 c28">3.3 Varying Intercept and Slope Model with a Single Predictor</span></h2><p class="c22 c31 c39"><span class="c4"></span></p><p class="c22 c31"><span class="c26 c23">We now extend the varying intercept model with a single predictor to allow both the intercept and the slope to vary randomly across incomes using the following model:</span></p><p class="c45"><img src="images/image17.png"><span class="c26 c23">,</span></p><p class="c45"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 281.50px; height: 70.00px;"><img alt="" src="images/image36.png" style="width: 281.50px; height: 70.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c22 c31"><span class="c23">We also use stan_lmer to fit Model 3.3. We use the default priors which are mostly similar to what was done in Model 1. Additionally, we are also required to specify a prior for the covariance matrix for </span><img src="images/image6.png"><span class="c23">and </span><img src="images/image18.png"><span class="c23">in this model. </span></p><p class="c22"><span class="c5 c13">M3_stanlmer &lt;- stan_lmer(formula = lfpr ~ state + (1 + state | income),<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; data = new_state_income,<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; seed = 349)<br>prior_summary(object = M3_stanlmer)</span></p><p class="c22"><span class="c5 c13">## Priors for model &#39;M3_stanlmer&#39; </span><span class="c5"><br></span><span class="c5 c13">## ------</span><span class="c5"><br></span><span class="c5 c13">## Intercept (after predictors centered)</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;~ normal(location = 0, scale = 10)</span><span class="c5"><br></span><span class="c5 c13">## &nbsp; &nbsp; &nbsp;**adjusted scale = 1.67</span><span class="c5"><br></span><span class="c5 c13">## </span><span class="c5"><br></span><span class="c5 c13">## Coefficients</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;~ normal(location = 0, scale = 2.5)</span><span class="c5"><br></span><span class="c5 c13">## &nbsp; &nbsp; &nbsp;**adjusted scale = 0.026</span><span class="c5"><br></span><span class="c5 c13">## </span><span class="c5"><br></span><span class="c5 c13">## Auxiliary (sigma)</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;~ exponential(rate = 1)</span><span class="c5"><br></span><span class="c5 c13">## &nbsp; &nbsp; &nbsp;**adjusted scale = 0.17 (adjusted rate = 1/adjusted scale)</span><span class="c5"><br></span><span class="c5 c13">## </span><span class="c5"><br></span><span class="c5 c13">## Covariance</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;~ decov(reg. = 1, conc. = 1, shape = 1, scale = 1)</span><span class="c5"><br></span><span class="c5 c13">## ------</span><span class="c5"><br></span><span class="c5 c13">## See help(&#39;prior_summary.stanreg&#39;) for more details</span></p><p class="c22"><span class="c5 c13">M3_stanlmer</span></p><p class="c22"><span class="c5 c13">## stan_lmer</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;family: &nbsp; &nbsp; &nbsp; gaussian [identity]</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;formula: &nbsp; &nbsp; &nbsp;lfpr ~ state + (1 + state | income)</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;observations: 1000</span><span class="c5"><br></span><span class="c5 c13">## ------</span><span class="c5"><br></span><span class="c5 c13">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Median MAD_SD</span><span class="c5"><br></span><span class="c5 c13">## (Intercept) 1.0 &nbsp; &nbsp;0.0 &nbsp; </span><span class="c5"><br></span><span class="c5 c13">## state &nbsp; &nbsp; &nbsp; 0.0 &nbsp; &nbsp;0.0 &nbsp; </span><span class="c5"><br></span><span class="c5 c13">## </span><span class="c5"><br></span><span class="c5 c13">## Auxiliary parameter(s):</span><span class="c5"><br></span><span class="c5 c13">## &nbsp; &nbsp; &nbsp; Median MAD_SD</span><span class="c5"><br></span><span class="c5 c13">## sigma 0.1 &nbsp; &nbsp;0.0 &nbsp; </span><span class="c5"><br></span><span class="c5 c13">## </span><span class="c5"><br></span><span class="c5 c13">## Error terms:</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;Groups &nbsp; Name &nbsp; &nbsp; &nbsp; &nbsp;Std.Dev. Corr </span><span class="c5"><br></span><span class="c5 c13">## &nbsp;income &nbsp; (Intercept) 0.0998 &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c5"><br></span><span class="c5 c13">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; state &nbsp; &nbsp; &nbsp; 0.0012 &nbsp; -0.29</span><span class="c5"><br></span><span class="c5 c13">## &nbsp;Residual &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.0633 &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c5"><br></span><span class="c5 c13">## Num. levels: income 68 </span><span class="c5"><br></span><span class="c5 c13">## </span><span class="c5"><br></span><span class="c5 c13">## Sample avg. posterior predictive distribution of y:</span><span class="c5"><br></span><span class="c5 c13">## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Median MAD_SD</span><span class="c5"><br></span><span class="c5 c13">## mean_PPD 0.9 &nbsp; &nbsp;0.0 &nbsp; </span><span class="c5"><br></span><span class="c5 c13">## </span><span class="c5"><br></span><span class="c5 c13">## ------</span><span class="c5"><br></span><span class="c5 c13">## * For help interpreting the printed output see ?print.stanreg</span><span class="c5"><br></span><span class="c5 c13">## * For info on the priors used see ?prior_summary.stanreg</span></p><p class="c42 c39" id="h.lnxbz9"><span class="c4"></span></p><p class="c42 c39"><span class="c4"></span></p><h2 class="c40"><span class="c27 c12">4. Conclusion</span></h2><p class="c22"><span class="c26 c23">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c22"><span class="c26 c23">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generally, using Multilevel Logistic Regression Model to predict whether a U.S. citizen participate in the job market or not is based on 7 variables, including sex, race, age, skill, annual income, state, and year, which could reach above 70% accuracy. </span></p><p class="c22 c31"><span class="c26 c23">Based on the inference results, we observe that the model does not capture the impact from the state to the labor force participation very well. Hence, by fixing state variable, we examine the remaining predictors and notice that income variable indicates a better fit. </span></p><p class="c22 c31"><span class="c26 c23">To analyze more about the effect of &nbsp;interactions among variables, we adopt Varying Intercept and Slope Model. However, this does not turn out to be better results. One reason might be that our grouping of regions into 4 parts is too board, which captures less information. The other reason might be that there is little correlation between state and income variable. </span></p><p class="c22 c31"><span class="c23">Therefore, considering more about the grouping of variables and the relationships among them might better improve our model to predict U.S. labor force participation rate.</span></p><h2 class="c40 c59"><span class="c35 c32"></span></h2><h2 class="c40 c59"><span class="c35 c32"></span></h2><div><p class="c39 c78"><span class="c4"></span></p></div></body></html>